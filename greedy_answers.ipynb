{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Generate greedy answers\n",
    "They are used to evaluate if answer is correct or incorrect. To see if an answer is correct/incorrect take fuzzy matching criterion $L(s, s') = \\mathbb{1}_{\\text{RougeL}(s, s') > 0.3}$ (page 7)\n",
    "\n",
    "\n",
    "Structure:\n",
    "\n",
    "```python \n",
    "{ 1131: {\"greedy_answer\": ..., \n",
    "         \"rouge_l_score\": ...\n",
    "        }, \n",
    "  4295: ...\n",
    "}\n",
    "```\n",
    "rouge_l_score stands for the Rouge-L score of the generated answer against the true answer. "
   ],
   "id": "88ffdcf85521522f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T12:58:14.887091Z",
     "start_time": "2024-06-10T12:58:14.867078Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, OPTForCausalLM\n",
    "import yaml\n",
    "import os\n",
    "import pickle\n",
    "from rouge_score import rouge_scorer\n",
    "from tqdm import tqdm\n",
    "\n",
    "with open(\"config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)"
   ],
   "id": "528b7f35a0370ddf",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T12:33:17.056481Z",
     "start_time": "2024-06-10T12:33:04.071182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load data\n",
    "model_dir = config[\"model_dir\"]\n",
    "data_trivia = load_dataset(\"trivia_qa\", \"rc.nocontext\")\n",
    "data_trivia = data_trivia.remove_columns([\"question_source\", \"entity_pages\", \"search_results\"])\n",
    "data_trivia_train = data_trivia[\"train\"]\n",
    "data_trivia_val = data_trivia[\"validation\"]"
   ],
   "id": "d89f95f85f45a310",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Resolving data files:   0%|          | 0/26 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "51a8cdf244ce46a181d165706035c380"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T12:33:32.399874Z",
     "start_time": "2024-06-10T12:33:32.301312Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ],
   "id": "cc9f5071c6b141dc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T12:39:03.897023Z",
     "start_time": "2024-06-10T12:37:11.628950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "checkpoint = config[\"checkpoint\"]\n",
    "tokenizer = AutoTokenizer.from_pretrained(f\"facebook/{checkpoint}\", cache_dir=model_dir)\n",
    "model = OPTForCausalLM.from_pretrained(f\"facebook/{checkpoint}\", cache_dir=model_dir)\n",
    "model = model.to(device)"
   ],
   "id": "88fe8bed8ecbc705",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T12:39:07.070858Z",
     "start_time": "2024-06-10T12:39:03.941647Z"
    }
   },
   "cell_type": "code",
   "source": [
    "selected_training_data = data_trivia_train.select(range(0, 10))\n",
    "ten_shot_prompt = \"\"\n",
    "for data in selected_training_data:\n",
    "    ten_shot_prompt += \"QUESTION:\" + data[\"question\"] + \"ANSWER:\" + data[\"answer\"][\"value\"] + \"\\n\"\n",
    "\n",
    "# Define stop tokens, use token on position 1 bc position 0 is special token\n",
    "stop_tokens = [\"Q:\", \"Question:\", \"QUESTION:\", \"questions:\", \" Q:\", \" Question:\", \" QUESTION:\", \" questions:\",\n",
    "               \"A:\", \"Answer:\", \"ANSWER:\", \"answers:\", \" A:\", \" Answer:\", \" ANSWER:\", \" answers:\", \"Answers:\",\n",
    "               \" Answers:\",\n",
    "               \"Topic:\", \" Topic:\", \"TOPIC:\", \" TOPIC:\", \".\", \" .\", \"...\", \" ...\", \"?\", \" ?\", \":\", \" :\", \"!\", \" !\"]\n",
    "stop_tokens = [[tokenizer(stop_token)[\"input_ids\"][1]] for stop_token in stop_tokens]\n",
    "\n",
    "# Define eos token\n",
    "eos_token = tokenizer(\"\\n\")[\"input_ids\"][1]\n",
    "tokenizer.pad_token_id = eos_token\n",
    "tokenizer.eos_token_id = eos_token\n",
    "\n",
    "# Maximum token length that generated answer can have\n",
    "max_new_tokens = config[\"max_output_length\"]"
   ],
   "id": "2333f03de136327d",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T12:54:52.175037Z",
     "start_time": "2024-06-10T12:54:52.156042Z"
    }
   },
   "cell_type": "code",
   "source": [
    "save_path = config[\"path_to_saved_generations\"]\n",
    "with open(os.path.join(save_path, \"group_indices.txt\"), \"r\") as f:\n",
    "    indices_questions = {int(i) for line in f for i in line.strip().split(\",\")}"
   ],
   "id": "dd96cf3fe6bb5de6",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T12:52:50.309927Z",
     "start_time": "2024-06-10T12:52:50.293928Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# https://thepythoncode.com/article/calculate-rouge-score-in-python#rouge-l\n",
    "scorer = rouge_scorer.RougeScorer([\"rougeL\"], use_stemmer=True)"
   ],
   "id": "1b01b8c4324e92e1",
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-10T13:12:45.020493Z",
     "start_time": "2024-06-10T12:58:19.075167Z"
    }
   },
   "source": [
    "if os.path.exists(os.path.join(save_path, \"greedy_answers.pkl\")):\n",
    "    with open(os.path.join(save_path, \"greedy_answers.pkl\"), \"rb\") as f:\n",
    "        result = pickle.load(f)\n",
    "else:\n",
    "    result = dict()\n",
    "\n",
    "for idx in tqdm(indices_questions):\n",
    "    if idx in result:\n",
    "        print(f\"Question {idx} already exists. Skipping...\")\n",
    "\n",
    "    result_question = dict()\n",
    "    question = ten_shot_prompt + \"QUESTION:\" + data_trivia_val[idx][\"question\"] + \"ANSWER:\"\n",
    "    answer = data_trivia_val[idx][\"answer\"][\"value\"]\n",
    "\n",
    "    inputs = tokenizer(question, padding=False, truncation=False, return_tensors=\"pt\").to(device)\n",
    "    length_input = inputs[\"input_ids\"].shape[1]\n",
    "\n",
    "    # Generate sequence by always taking token with max probability (greedy)\n",
    "    output_generate = model.generate(inputs.input_ids,\n",
    "                                     max_new_tokens=max_new_tokens,\n",
    "                                     eos_token_id=eos_token,\n",
    "                                     bad_words_ids=stop_tokens)\n",
    "\n",
    "    output = tokenizer.batch_decode(output_generate[0][length_input:], skip_special_tokens=True)\n",
    "    output = \"\".join(output).replace(\"\\n\", \"\")\n",
    "    result_question[\"greedy_answer\"] = output\n",
    "    rouge_l_score = scorer.score(answer, output)[\"rougeL\"].fmeasure\n",
    "    result_question[\"rouge_l_score\"] = rouge_l_score\n",
    "    result[idx] = result_question\n",
    "    \n",
    "    # Save new dictionary\n",
    "    with open(os.path.join(save_path, \"greedy_answers.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(result, f)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4484/4484 [14:25<00:00,  5.18it/s]\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d0bba5de48398a04"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
