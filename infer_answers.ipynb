{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Group semantically equivalent answers into bins for each question\n",
    "Model: Deberta (https://huggingface.co/sileod/deberta-v3-large-tasksource-nli)"
   ],
   "id": "7559db96c7f2ccd0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T08:46:50.646376Z",
     "start_time": "2024-06-15T08:46:44.885918Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import yaml\n",
    "import os\n",
    "import pickle\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "with open(\"config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)"
   ],
   "id": "d36e7253f9fd0793",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T20:26:51.643652Z",
     "start_time": "2024-06-13T20:26:51.509882Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device"
   ],
   "id": "a2df06ce282e404b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T08:50:08.694073Z",
     "start_time": "2024-06-15T08:50:08.680074Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_dir = config[\"model_dir\"]\n",
    "save_path = config[\"path_to_saved_generations\"]"
   ],
   "id": "5115d3a4b654d3d3",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T20:30:37.662961Z",
     "start_time": "2024-06-13T20:29:53.191202Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_name = \"sileod/deberta-v3-large-tasksource-nli\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=model_dir)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, cache_dir=model_dir).to(device)"
   ],
   "id": "402f3ff802a143da",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T08:49:46.788583Z",
     "start_time": "2024-06-15T08:49:46.772069Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_pickle_files(folder):\n",
    "    data_groups = []\n",
    "    pickle_files = glob.glob(f\"{folder}/group*.pkl\")\n",
    "    for pickle_file in pickle_files:\n",
    "        with open(pickle_file, \"rb\") as f:\n",
    "            data_groups.append(pickle.load(f))\n",
    "\n",
    "    return data_groups"
   ],
   "id": "6cffe20802782df5",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Example\n",
    "Two answers are semantically equivalent if \n",
    "- \"Question: *question* Answer: *generated answer*\" $\\Rightarrow$ \"Question: *question* Answer: *true answer*\" **and** \n",
    "- \"Question: *question* Answer: *true answer*\" $\\Rightarrow$ \"Question: *question* Answer: *generated answer*\"\n",
    "\n",
    "= Bidirectional entailment"
   ],
   "id": "6b6e79e288b06c55"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many continents does the world have? Answer: There are seven continents. => Question: How many continents does the world have? Answer: Seven.\n",
      "{'entailment': 99.4, 'neutral': 0.6, 'contradiction': 0.0}\n",
      "\n",
      "Question: How many continents does the world have? Answer: Seven. => Question: How many continents does the world have? Answer: There are seven continents.\n",
      "{'entailment': 97.1, 'neutral': 2.9, 'contradiction': 0.0}\n"
     ]
    }
   ],
   "execution_count": 11,
   "source": [
    "question = \"Question: How many continents does the world have?\"\n",
    "sequence1 = \"Answer: There are seven continents.\"\n",
    "sequence2 = \"Answer: Seven.\"\n",
    "\n",
    "# Direction 1\n",
    "premise = question + \" \" + sequence1\n",
    "hypothesis = question + \" \" + sequence2\n",
    "print(premise + \" => \" + hypothesis)\n",
    "input = tokenizer(premise, hypothesis, return_tensors=\"pt\")\n",
    "output = model(input[\"input_ids\"].to(device))\n",
    "prediction = torch.softmax(output[\"logits\"][0], -1).tolist()\n",
    "label_names = [\"entailment\", \"neutral\", \"contradiction\"]\n",
    "prediction = {name: round(float(pred) * 100, 1) for pred, name in zip(prediction, label_names)}\n",
    "print(prediction, end=\"\\n\\n\")\n",
    "\n",
    "# Direction 2\n",
    "premise = question + \" \" + sequence2\n",
    "hypothesis = question + \" \" + sequence1\n",
    "print(premise + \" => \" + hypothesis)\n",
    "input = tokenizer(premise, hypothesis, return_tensors=\"pt\")\n",
    "output = model(input[\"input_ids\"].to(device))\n",
    "prediction = torch.softmax(output[\"logits\"][0], -1).tolist()\n",
    "prediction = {name: round(float(pred) * 100, 1) for pred, name in zip(prediction, label_names)}\n",
    "print(prediction)"
   ],
   "id": "1f564835b3b4a12c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Save lexical equivalence groups\n",
    "Used to see the distinct words in an equivalence class\n",
    "\n",
    "Structure to save them\n",
    "```python \n",
    "{ 1131: {\"question\": ..., \n",
    "         \"true_answer\": ..., \n",
    "         \"temperature_0.25\": {\"answers\": [...], \"probabilities\": [...], \"length_output\": [...], \"lexical_eq_groups\": [0, 1, 0, 2, 3, ...]},\n",
    "         \"temperature_0.5\": {\"answers\": [...], \"probabilities\": [...], \"length_output\": [...], \"lexical_eq_groups\": [...]},\n",
    "         \"temperature_1\": {\"answers\": [...], \"probabilities\": [...], \"length_output\": [...], \"lexical_eq_groups\": [...]},\n",
    "         \"temperature_1.5\": {\"answers\": [...], \"probabilities\": [...], \"length_output\": [...], \"lexical_eq_groups\": [...]},\n",
    "         \"beam_20\": {\"answers\": [...], \"probabilities\": [...], \"length_output\": [...], \"lexical_eq_groups\": [...]}\n",
    "        }, \n",
    "  4295: ...\n",
    "}\n",
    "```\n",
    "where the numbers in lexical_eq_groups stand for the group they belong to."
   ],
   "id": "d30d627554808fdf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T19:36:10.632320Z",
     "start_time": "2024-06-13T19:36:06.092188Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = load_pickle_files(save_path)\n",
    "config_keys = [f\"temperature_{t}\" for t in config[\"temperatures\"]] + [f\"beam_{b}\" for b in config[\"n_beams\"]]"
   ],
   "id": "295e322e3bd6dd39",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T19:36:52.339418Z",
     "start_time": "2024-06-13T19:36:46.882366Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for group_nr, group in enumerate(data):\n",
    "    for question_id in tqdm(group):\n",
    "        for k in config_keys:\n",
    "            answers = group[question_id][k][\"answers\"]\n",
    "            lexical_eq_groups = [-1] * len(answers)\n",
    "            group_count = 0\n",
    "\n",
    "            for i in range(len(answers)):\n",
    "                if lexical_eq_groups[i] == -1:\n",
    "                    lexical_eq_groups[i] = group_count\n",
    "                    for j in range(i + 1, len(answers)):\n",
    "                        if answers[i] == answers[j]:\n",
    "                            lexical_eq_groups[j] = group_count\n",
    "                    group_count += 1\n",
    "            group[question_id][k][\"lexical_eq_groups\"] = lexical_eq_groups\n",
    "\n",
    "    # Save result\n",
    "    with open(os.path.join(save_path, f\"group{group_nr}.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(group, f)"
   ],
   "id": "b8eb4caa60728d1f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 16643.20it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 22476.31it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 22723.87it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 22207.71it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 21737.55it/s]\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Bidirectional Entailment Clustering\n",
    "Used to calculate semantic entropy\n",
    "\n",
    "Structure to save them\n",
    "```python \n",
    "{ 1131: {\"question\": ..., \n",
    "         \"true_answer\": ..., \n",
    "         \"temperature_0.25\": {\"answers\": [...], \"probabilities\": [...], \"length_output\": [...], \"lexical_eq_groups\": [...], \"semantic_eq_groups\": [...]},\n",
    "         \"temperature_0.5\": {\"answers\": [...], \"probabilities\": [...], \"length_output\": [...], \"lexical_eq_groups\": [...], \"semantic_eq_groups\": [...]},\n",
    "         \"temperature_1\": {\"answers\": [...], \"probabilities\": [...], \"length_output\": [...], \"lexical_eq_groups\": [...], \"semantic_eq_groups\": [...]},\n",
    "         \"temperature_1.5\": {\"answers\": [...], \"probabilities\": [...], \"length_output\": [...], \"lexical_eq_groups\": [...], \"semantic_eq_groups\": [...]},\n",
    "         \"beam_20\": {\"answers\": [...], \"probabilities\": [...], \"length_output\": [...], \"lexical_eq_groups\": [...], \"semantic_eq_groups\": [...]}\n",
    "        }, \n",
    "  4295: ...\n",
    "}\n",
    "```\n",
    "where the numbers in semantic_eq_groups stand for the semantic equivalence class they belong to.\n",
    "\n",
    "The algo is written as pseudocode on page 15."
   ],
   "id": "ae14b87ee3d8ae27"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T20:30:57.857382Z",
     "start_time": "2024-06-13T20:30:57.839839Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def bidirectional_entailment(question, answer1, answer2):\n",
    "    \"\"\"\n",
    "    Tests whether bidirectional entailment Question answer1 <=> Question answer2 holds\n",
    "    :return: True for bidirectional entailment, False otherwise\n",
    "    \"\"\"\n",
    "    true_answer = \"Answer: \" + answer1\n",
    "    question = \"Question: \" + question\n",
    "    generated_answer = \"Answer: \" + answer2\n",
    "\n",
    "    # First direction\n",
    "    premise = question + \" \" + generated_answer\n",
    "    hypothesis = question + \" \" + true_answer\n",
    "    input = tokenizer(premise, hypothesis, return_tensors=\"pt\")\n",
    "    output = model(input[\"input_ids\"].to(device))\n",
    "    prediction = torch.argmax(output[\"logits\"][0], dim=-1).item()  # 0: entail, 1: neutral, 2: contradiction\n",
    "\n",
    "    # Only if first direction entailment: look at second direction\n",
    "    if prediction == 0:\n",
    "        input = tokenizer(hypothesis, premise, return_tensors=\"pt\")\n",
    "        output = model(input[\"input_ids\"].to(device))\n",
    "        prediction = torch.argmax(output[\"logits\"][0], dim=-1).item()\n",
    "        if prediction == 0:\n",
    "            return True\n",
    "\n",
    "    return False"
   ],
   "id": "289786d2bf38112",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T20:30:59.476204Z",
     "start_time": "2024-06-13T20:30:59.455175Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def bidirectional_entailment_clustering(question, answers):\n",
    "    # Save as list as order is needed (\"Use first sequence for each semantic-class\")\n",
    "    # Only save indices of answers\n",
    "    meanings = [[0]]\n",
    "\n",
    "    for m in range(1, len(answers)):\n",
    "        added = False\n",
    "        for equivalence_class_nr, equivalence_class in enumerate(meanings):\n",
    "            # Use first sequence for each semantic class\n",
    "            s_c = answers[equivalence_class[0]]\n",
    "            if bidirectional_entailment(question, s_c, answers[m]):\n",
    "                meanings[equivalence_class_nr].append(m)\n",
    "                added = True\n",
    "                break\n",
    "        if not added:\n",
    "            meanings.append([m])\n",
    "\n",
    "    return meanings"
   ],
   "id": "2ca1481397ce8274",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T20:31:01.934235Z",
     "start_time": "2024-06-13T20:31:00.932595Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = load_pickle_files(save_path)\n",
    "config_keys = [f\"temperature_{t}\" for t in config[\"temperatures\"]] + [f\"beam_{b}\" for b in config[\"n_beams\"]]"
   ],
   "id": "f5f7b97805bf93f9",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T17:33:42.030597Z",
     "start_time": "2024-06-14T17:32:33.484796Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for group_nr, group in enumerate(data):\n",
    "    for question_id in tqdm(group):\n",
    "        for k in config_keys:\n",
    "            # Already created\n",
    "            if \"semantic_eq_groups\" in group[question_id][k]:\n",
    "                continue\n",
    "\n",
    "            answers = group[question_id][k][\"answers\"]\n",
    "            question = group[question_id][\"question\"]\n",
    "            semantic_eq_groups = [-1] * len(answers)\n",
    "\n",
    "            semantic_clusters = bidirectional_entailment_clustering(question, answers)\n",
    "            for cluster_id, cluster in enumerate(semantic_clusters):\n",
    "                for index in cluster:\n",
    "                    semantic_eq_groups[index] = cluster_id\n",
    "\n",
    "            group[question_id][k][\"semantic_eq_groups\"] = semantic_eq_groups\n",
    "\n",
    "        # Save result\n",
    "        with open(os.path.join(save_path, f\"group{group_nr}.pkl\"), \"wb\") as f:\n",
    "            pickle.dump(group, f)\n"
   ],
   "id": "16e443878c17325",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:13<00:00, 72.26it/s]\n",
      "100%|██████████| 1000/1000 [00:13<00:00, 73.04it/s]\n",
      "100%|██████████| 1000/1000 [00:13<00:00, 72.49it/s]\n",
      "100%|██████████| 1000/1000 [00:13<00:00, 73.66it/s]\n",
      "100%|██████████| 1000/1000 [00:13<00:00, 73.39it/s]\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Test if correctly saved",
   "id": "4604643c75e00e6d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T17:34:38.037620Z",
     "start_time": "2024-06-14T17:34:37.696926Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = load_pickle_files(save_path)\n",
    "with open(os.path.join(save_path, \"group_indices.txt\"), \"r\") as f:\n",
    "    indices_groups = [[int(i) for i in line.strip().split(\",\")] for line in f]\n",
    "\n",
    "for group_nr, group in enumerate(data):\n",
    "\n",
    "    assert len(group) == 1000\n",
    "    assert set(group.keys()) == set(indices_groups[group_nr])\n",
    "    for question_id in group.keys():\n",
    "        for k in config_keys:\n",
    "            assert len(group[question_id][k][\"semantic_eq_groups\"]) == config[\"n_generations_per_answer\"]\n",
    "    print(f\"group{group_nr} - Yes.\")"
   ],
   "id": "83d1463062b02997",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group0 - Yes.\n",
      "group1 - Yes.\n",
      "group2 - Yes.\n",
      "group3 - Yes.\n",
      "group4 - Yes.\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Analysis of result\n",
    "Most of the time, this approach correctly identifies the equivalence classes. Examples:"
   ],
   "id": "53f81de43f3c0fba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 7,
   "source": "data = load_pickle_files(save_path)",
   "id": "28a24609f2d359d2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: On what date in 1969 did Neil Armstrong first set foot on the Moon?\n",
      "August 20 (Group: 0)\n",
      "July 20 (Group: 1)\n",
      "August 20th (Group: 0)\n",
      "July 20th (Group: 1)\n",
      "August 20th (Group: 0)\n",
      "20th (Group: 2)\n",
      "20th (Group: 2)\n",
      "July 20 (Group: 1)\n",
      "July 20 (Group: 1)\n",
      "July 20th (Group: 1)\n",
      "\n",
      "Question: The Naismith Award is presented in which sport?\n",
      "The game of basketball (Group: 0)\n",
      "All Sports (Group: 1)\n",
      "basketball (Group: 0)\n",
      "American Football, Basketball and Baseball (Group: 2)\n",
      "Hockey (Group: 3)\n",
      "basketball (Group: 0)\n",
      "basketball (Group: 0)\n",
      "NBA (Group: 4)\n",
      "Baseball (Group: 5)\n",
      "Soccer (Group: 6)\n",
      "\n",
      "Question: In a standard deck of cards, how many Kings have a moustache?\n",
      "Seven (Group: 0)\n",
      "7 (Group: 0)\n",
      "6 (Group: 1)\n",
      "2 (Group: 2)\n",
      "2 (Group: 2)\n",
      "2 (Group: 2)\n",
      "Seven (Group: 0)\n",
      "Seven (Group: 0)\n",
      "5 (Group: 3)\n",
      "2 (Group: 2)\n"
     ]
    }
   ],
   "execution_count": 178,
   "source": [
    "print(f\"Question: {data[3][76]['question']}\")\n",
    "for a, entail in zip(data[3][76][\"temperature_0.5\"][\"answers\"], data[3][76][\"temperature_0.5\"][\"semantic_eq_groups\"]):\n",
    "    print(f\"{a} (Group: {entail})\")\n",
    "\n",
    "print(f\"\\nQuestion: {data[0][129]['question']}\")\n",
    "for a, entail in zip(data[0][129][\"temperature_1\"][\"answers\"], data[0][129][\"temperature_1\"][\"semantic_eq_groups\"]):\n",
    "    print(f\"{a} (Group: {entail})\")\n",
    "\n",
    "print(f\"\\nQuestion: {data[2][354]['question']}\")\n",
    "for a, entail in zip(data[2][354][\"temperature_0.25\"][\"answers\"],\n",
    "                     data[2][354][\"temperature_0.25\"][\"semantic_eq_groups\"]):\n",
    "    print(f\"{a} (Group: {entail})\")"
   ],
   "id": "1a82ab4506b0b56e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Even if answers like \"July 20\"/\"July 20th\" or \"Seven\"/\"7\" are not lexical equivalent, they still belong to the same equivalence class. Answers like \"American Football, Basketball and Baseball\" that contain parts of other answers (\"basketball/\"Baseball\") still form their own equivalence class.",
   "id": "358f706c79f649f5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "There are two potential problems of the bidirectional entailment clustering algo:\n",
    "1. Due to the transitivity of an equivalence relation, all elements in an equivalence class should entail each other. However, with this implementation, that does not always have to hold true. An answer is placed into an equivalence class by only comparing it to the first element. Despite this, all cases I had a look at seemed to be fine. In the paper, they observe the same thing (page 14).\n",
    "2. The entailment determined by using a model is sometimes inaccurate. Especially in the beam sampling cases, more equivalence classes than actually needed are formed."
   ],
   "id": "5957ae18dead8861"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \"Which German social economist of Jewish descent, expelled from Germany and France, co-wrote in London \"\"The Communist Manifesto\"\" and \"\"Das Kapital\"\"?\"\n",
      "Karl Marx (Group: 0)\n",
      "Karl Marx (1818-1883) (Group: 1)\n",
      "Karl Marx and Friedrich Engels (Group: 2)\n",
      "Karl Marx (1818-1883) and Friedrich Engels (1817-1892) (Group: 3)\n",
      "Karl Marx (1818-1883) and Friedrich Engels (1819-1892) (Group: 4)\n",
      "Karl Marx (1818-1883) and Friedrich Engels (1817-1876) (Group: 5)\n",
      "Karl Marx (1818-1883) and Friedrich Engels (1817-1896) (Group: 6)\n",
      "Karl Marx (1818-1883) and Friedrich Engels (1819-1894) (Group: 7)\n",
      "Karl Liebknecht (Group: 8)\n",
      "Karl Marx (1818-1883) and Friedrich Engels (1817-1894) (Group: 9)\n"
     ]
    }
   ],
   "execution_count": 9,
   "source": [
    "print(f\"Question: {data[0][12962]['question']}\")\n",
    "for a, entail in zip(data[0][12962][\"beam_20\"][\"answers\"], data[0][12962][\"beam_20\"][\"lexical_eq_groups\"]):\n",
    "    print(f\"{a} (Group: {entail})\")"
   ],
   "id": "751dabf596e07281"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "\"Karl Marx\" should be in the same equivalence class as \"Karl Marx (1818 - 1883)\". The majority of other answers are also similar and only vary in the years that was not even asked.",
   "id": "c039e03ba8140b66"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T14:25:16.090920Z",
     "start_time": "2024-06-15T14:25:16.075920Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "280194201b16d884",
   "outputs": [],
   "execution_count": 167
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
