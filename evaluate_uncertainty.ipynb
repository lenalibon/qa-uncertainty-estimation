{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Evaulate uncertainty measure\n",
    "- To evaluate different uncertainty measure, use AUROC. \n",
    "- Uncertainty measure expected to be higher for incorrect answers and lower for correct answers. As we want to show the relationship incorrect answer -> High uncertainty, incorrect answers are encoded with label 1, correct answers with label 0 \n",
    "- Compute AUROC score for each uncertainty measure with sklearn.metrics.roc_auc_score([0, 0, 0, 1, 1, 0, ...], [semantic entropy scores of the answers])\n",
    "\n",
    "\n",
    "Page 17: They compare Rouge-L > 0.3, Rouge-L > 0.5, exact matching, semantic matching \n"
   ],
   "id": "29c486761075e36e"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import yaml\n",
    "import glob\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "with open(\"config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)"
   ],
   "id": "98f78f76fad19b6a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T17:16:37.773457Z",
     "start_time": "2024-06-15T17:16:37.758443Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_pickle_files(folder):\n",
    "    data_groups = []\n",
    "    pickle_files = glob.glob(f\"{folder}/group*.pkl\")\n",
    "    for pickle_file in pickle_files:\n",
    "        with open(pickle_file, \"rb\") as f:\n",
    "            data_groups.append(pickle.load(f))\n",
    "\n",
    "    return data_groups"
   ],
   "id": "875b17d3b889fcb1",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T17:16:38.661334Z",
     "start_time": "2024-06-15T17:16:38.490743Z"
    }
   },
   "cell_type": "code",
   "source": [
    "save_path = config[\"path_to_saved_generations\"]\n",
    "data_groups = load_pickle_files(save_path)\n",
    "keys_data = [f\"temperature_{temp}\" for temp in config[\"temperatures\"]] + [f\"beam_{beam}\" for beam in config[\"n_beams\"]]"
   ],
   "id": "cafc0a497c6212d2",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Save results",
   "id": "8aaa263579425297"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T17:16:39.879139Z",
     "start_time": "2024-06-15T17:16:39.862155Z"
    }
   },
   "cell_type": "code",
   "source": [
    "general_columns = [\"question_id\", \"group\"]\n",
    "correct_columns = [\"rougel_0.3\", \"rougel_0.5\", \"rouge1_0.5\", \"entailment\", \"label_by_hand\"]\n",
    "predictive_entropy_columns = [f\"pred_entropy_temperature_{s}\" for s in config[\"temperatures\"]] + [\n",
    "    f\"pred_entropy_beam_{s}\" for s in config[\"n_beams\"]]\n",
    "length_normalized_entropy_columns = [f\"length_normalized_pred_entropy_temperature_{s}\" for s in\n",
    "                                     config[\"temperatures\"]] + [\n",
    "                                        f\"length_normalized_pred_entropy_beam_{s}\" for s in config[\"n_beams\"]]\n",
    "n_semantically_distinct_columns = [f\"n_semantically_distinct_temperature_{s}\" for s in config[\"temperatures\"]] + [\n",
    "    f\"n_semantically_distinct_beam_{s}\" for s in config[\"n_beams\"]]\n",
    "semantic_entropy_columns = [f\"sem_entropy_temperature_{s}\" for s in config[\"temperatures\"]] + [\n",
    "    f\"sem_entropy_beam_{s}\" for s in config[\"n_beams\"]]\n",
    "\n",
    "results = pd.DataFrame(\n",
    "    columns=general_columns + correct_columns + predictive_entropy_columns + length_normalized_entropy_columns + n_semantically_distinct_columns + semantic_entropy_columns)"
   ],
   "id": "1401ba857af09627",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-06-15T17:16:45.402602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_groups = load_pickle_files(save_path)\n",
    "\n",
    "for group_nr, group_info in enumerate(data_groups):\n",
    "    for question_idx in group_info.keys():\n",
    "        new_row = {\"question_id\": question_idx, \"group\": group_nr}\n",
    "        results = pd.concat([results, pd.DataFrame([new_row])], ignore_index=True)"
   ],
   "id": "6032d4dfde013a05",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Store it for now\n",
    "results.to_csv(os.path.join(save_path, \"results.csv\"), index=False)"
   ],
   "id": "102c405292699b5b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Predictive Entropy\n",
    "\n",
    "The predictive entropy is defined as:\n",
    "$$PE(x) = H[p(y \\mid x)] = - \\sum_{y} p(y \\mid x) \\ln p(y \\mid x)$$\n",
    "\n",
    "Since this is the expected value of $\\ln p(y \\mid x)$, Monte Carlo sampling approximates it by averaging log-probabilities from sampled outcomes. Thus, the Monte Carlo estimator is:\n",
    "$$PE(x) \\approx - \\frac{1}{n}  \\sum_{i = 1}^{n} \\ln p(y_i \\mid x)$$ where $n$ is the number of sampled answers for the question $x$."
   ],
   "id": "9ba879e09bf27a93"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-15T15:19:24.678910Z",
     "start_time": "2024-06-15T15:19:24.666479Z"
    }
   },
   "source": [
    "def predictive_entropy(probabilities, lexical_eq_classes):\n",
    "    equivalence_classes = set(lexical_eq_classes)\n",
    "\n",
    "    probability_eq_class = np.zeros(len(equivalence_classes))\n",
    "\n",
    "    # Sum probabilities for each equivalence class\n",
    "    for i, eq_class in enumerate(equivalence_classes):\n",
    "        prob_sum = np.sum([probabilities[j] for j in range(len(probabilities)) if lexical_eq_classes[j] == eq_class])\n",
    "        probability_eq_class[i] = np.log(prob_sum)\n",
    "\n",
    "    return -1 / len(equivalence_classes) * np.sum(probability_eq_class)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T15:25:12.230794Z",
     "start_time": "2024-06-15T15:25:12.216795Z"
    }
   },
   "cell_type": "code",
   "source": "predictive_entropy_scores = {k: [] for k in keys_data}",
   "id": "5cfaa1845b0d6a2d",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4b7731c49f1de79a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Length-normalised predictive entropy",
   "id": "73b6ff75d925ac5f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Number of semantically distinct answers",
   "id": "755ebd5ab90b8e04"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e3d189ea8bff3ee0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Semantic Entropy",
   "id": "3c829e3fa022a789"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T15:26:36.916104Z",
     "start_time": "2024-06-15T15:26:36.898098Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def semantic_entropy(probabilities, semantic_eq_classes):\n",
    "    equivalence_classes = set(semantic_eq_classes)\n",
    "\n",
    "    probability_eq_class = np.zeros(len(equivalence_classes))\n",
    "\n",
    "    # Sum probabilities for each equivalence class\n",
    "    for i, eq_class in enumerate(equivalence_classes):\n",
    "        prob_sum = np.sum([probabilities[j] for j in range(len(probabilities)) if semantic_eq_classes[j] == eq_class])\n",
    "        probability_eq_class[i] = np.log(prob_sum)\n",
    "\n",
    "    return -1 / len(equivalence_classes) * np.sum(probability_eq_class)"
   ],
   "id": "1011b74181cbb023",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5c1a62ea906946e5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Plots\n",
    "- Bar plot: x-axis Semantic entropy, normalised entropy, entropy; y-axis: AUROC (page 2)\n",
    "- Table 2\n",
    "- x-axis Temperature, y-axis AUROC (2 lines: semantic entropy, length-normalised entropy)\n",
    "- x-axis number samples used to estimate entropy, y-axis AUROC; lines: Semantic entropy, length-normalised entropy, entropy\n",
    "- "
   ],
   "id": "2050a3b6c87b5977"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
