{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate answers with TriviaQA\n",
    "Used for closed-book QA (=without supporting paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T19:51:41.896792Z",
     "start_time": "2024-06-07T19:51:34.554545Z"
    }
   },
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "from transformers import AutoTokenizer, OPTForCausalLM\n",
    "import numpy as np\n",
    "from utils import calculate_probability_sequence\n",
    "\n",
    "torch.cuda.empty_cache()"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T19:51:41.912764Z",
     "start_time": "2024-06-07T19:51:41.898762Z"
    }
   },
   "source": "model_dir = \"models\"",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Load and inspect data"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T19:51:56.369098Z",
     "start_time": "2024-06-07T19:51:43.385957Z"
    }
   },
   "source": [
    "data_trivia = load_dataset(\"trivia_qa\", \"rc.nocontext\")\n",
    "\n",
    "# Remove unnecessary columns\n",
    "data_trivia = data_trivia.remove_columns([\"question_source\", \"entity_pages\", \"search_results\"])\n",
    "\n",
    "# Split to train, validation, test set\n",
    "data_trivia_train = data_trivia[\"train\"]\n",
    "data_trivia_val = data_trivia[\"validation\"]\n",
    "data_trivia_test = data_trivia[\"test\"]\n",
    "\n",
    "print(f\"Trivia QA Training Set Size: {data_trivia_train.shape}\")\n",
    "print(f\"Trivia QA Validation Set Size: {data_trivia_val.shape}\")\n",
    "print(f\"Trivia QA Test Set Size: {data_trivia_test.shape}\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Resolving data files:   0%|          | 0/26 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c8de51e02a074d9db7069f00edd8eb9a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trivia QA Training Set Size: (138384, 3)\n",
      "Trivia QA Validation Set Size: (17944, 3)\n",
      "Trivia QA Test Set Size: (17210, 3)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T19:51:56.385066Z",
     "start_time": "2024-06-07T19:51:56.371070Z"
    }
   },
   "source": [
    "print(\"Training Set\")\n",
    "for i in range(2):\n",
    "    print(f\"Q: {data_trivia_train[i]['question']}\\nA: {data_trivia_train[i]['answer']['value']}\\n\")\n",
    "\n",
    "print(\"Validation Set\")\n",
    "for i in range(2):\n",
    "    print(f\"Q: {data_trivia_val[i]['question']}\\nA: {data_trivia_val[i]['answer']['value']}\\n\")\n",
    "\n",
    "print(\"Test Set\")\n",
    "for i in range(2):\n",
    "    print(f\"Q: {data_trivia_test[i]['question']}\\nA: {data_trivia_test[i]['answer']['value']}\\n\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set\n",
      "Q: Which American-born Sinclair won the Nobel Prize for Literature in 1930?\n",
      "A: Sinclair Lewis\n",
      "\n",
      "Q: Where in England was Dame Judi Dench born?\n",
      "A: York\n",
      "\n",
      "Validation Set\n",
      "Q: Who was the man behind The Chipmunks?\n",
      "A: David Seville\n",
      "\n",
      "Q: Which Lloyd Webber musical premiered in the US on 10th December 1993?\n",
      "A: Sunset Boulevard\n",
      "\n",
      "Test Set\n",
      "Q: Asmara international airport is in which country?\n",
      "A: <unk>\n",
      "\n",
      "Q: At whose concert were 11 people trampled to death in Ohio in 1979?\n",
      "A: <unk>\n",
      "\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Training set: Used for few shot prompt\n",
    "- Validation set: Estimate uncertainty of model\n",
    "\n",
    "Reason: Later evaluate how good uncertainty measure is by using AUROC --> Need correct answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run some predictions\n",
    "Same as in the paper, the OPT model is used. Because of computational constraints, I use the OPT model with 1.3B parameters. The smallest model used in the paper is the one with 2.7B parameters (see page 7)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T19:51:58.736985Z",
     "start_time": "2024-06-07T19:51:58.644490Z"
    }
   },
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T19:53:05.691561Z",
     "start_time": "2024-06-07T19:52:22.170203Z"
    }
   },
   "source": [
    "# Causal LM: model predicts next token \n",
    "checkpoint = \"opt-1.3B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(f\"facebook/{checkpoint}\", cache_dir=model_dir)\n",
    "model = OPTForCausalLM.from_pretrained(f\"facebook/{checkpoint}\", cache_dir=model_dir)\n",
    "model = model.to(device)"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T19:53:44.894997Z",
     "start_time": "2024-06-07T19:53:05.698564Z"
    }
   },
   "source": [
    "# Try out examples\n",
    "for i in range(5):\n",
    "    question = \"Q: \" + data_trivia_val[i][\"question\"] + \" A:\"\n",
    "    answer = data_trivia_val[i][\"answer\"][\"value\"]\n",
    "\n",
    "    inputs = tokenizer(question, padding=False, truncation=False, return_tensors=\"pt\").to(device)\n",
    "    length_input = inputs[\"input_ids\"].shape[1]\n",
    "\n",
    "    generate_ids = model.generate(inputs.input_ids, max_length=256)\n",
    "    # Only decode answer and not posed question\n",
    "    output = tokenizer.batch_decode(generate_ids[0][length_input:], skip_special_tokens=True)\n",
    "\n",
    "    print(question)\n",
    "    print(f\"True answer: {answer}\")\n",
    "    print(f\"Model output: {''.join(output)}\")\n",
    "    print(\"-------------------------\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Who was the man behind The Chipmunks? A:\n",
      "True answer: David Seville\n",
      "Model output:  The man behind The Chipmunks was a man named Chip.\n",
      "\n",
      "Q: Who was the man behind The Chipmunks? A: The man behind The Chipmunks was a man named Chip.\n",
      "\n",
      "Q: Who was the man behind The Chipmunks? A: The man behind The Chipmunks was a man named Chip.\n",
      "\n",
      "Q: Who was the man behind The Chipmunks? A: The man behind The Chipmunks was a man named Chip.\n",
      "\n",
      "Q: Who was the man behind The Chipmunks? A: The man behind The Chipmunks was a man named Chip.\n",
      "\n",
      "Q: Who was the man behind The Chipmunks? A: The man behind The Chipmunks was a man named Chip.\n",
      "\n",
      "Q: Who was the man behind The Chipmunks? A: The man behind The Chipmunks was a man named Chip.\n",
      "\n",
      "Q: Who was the man behind The Chipmunks? A: The man behind The Chipmunks was a man named Chip.\n",
      "\n",
      "Q: Who was the man behind The Chipmunks? A: The man behind The Chipmunks was a\n",
      "-------------------------\n",
      "Q: Which Lloyd Webber musical premiered in the US on 10th December 1993? A:\n",
      "True answer: Sunset Boulevard\n",
      "Model output:  The Phantom of the Opera\n",
      "\n",
      "Q: Which Lloyd Webber musical premiered in the US on 10th December 1993? A: The Phantom of the Opera\n",
      "\n",
      "Q: Which Lloyd Webber musical premiered in the US on 10th December 1993? A: The Phantom of the Opera\n",
      "\n",
      "Q: Which Lloyd Webber musical premiered in the US on 10th December 1993? A: The Phantom of the Opera\n",
      "\n",
      "Q: Which Lloyd Webber musical premiered in the US on 10th December 1993? A: The Phantom of the Opera\n",
      "\n",
      "Q: Which Lloyd Webber musical premiered in the US on 10th December 1993? A: The Phantom of the Opera\n",
      "\n",
      "Q: Which Lloyd Webber musical premiered in the US on 10th December 1993? A: The Phantom of the Opera\n",
      "\n",
      "Q: Which Lloyd Webber musical premiered in the US on 10th December 1993? A: The Phantom of the Opera\n",
      "\n",
      "Q: Which Lloyd Webber musical premiered in the US on 10th December 1993? A: The Phantom of the Opera\n",
      "\n",
      "Q: Which Lloyd Webber musical premiered in the US on 10th December 1993? A: The Phantom\n",
      "-------------------------\n",
      "Q: Who was the next British Prime Minister after Arthur Balfour? A:\n",
      "True answer: Campbell-Bannerman\n",
      "Model output:  Winston Churchill.\n",
      "\n",
      "Q: Who was the next British Prime Minister after Arthur Balfour? A: Winston Churchill.\n",
      "\n",
      "Q: Who was the next British Prime Minister after Arthur Balfour? A: Winston Churchill.\n",
      "\n",
      "Q: Who was the next British Prime Minister after Arthur Balfour? A: Winston Churchill.\n",
      "\n",
      "Q: Who was the next British Prime Minister after Arthur Balfour? A: Winston Churchill.\n",
      "\n",
      "Q: Who was the next British Prime Minister after Arthur Balfour? A: Winston Churchill.\n",
      "\n",
      "Q: Who was the next British Prime Minister after Arthur Balfour? A: Winston Churchill.\n",
      "\n",
      "Q: Who was the next British Prime Minister after Arthur Balfour? A: Winston Churchill.\n",
      "\n",
      "Q: Who was the next British Prime Minister after Arthur Balfour? A: Winston Churchill.\n",
      "\n",
      "Q: Who was the next British Prime Minister after Arthur Balfour? A: Winston Churchill.\n",
      "\n",
      "Q: Who was the next British Prime Minister after Arthur Balfour? A: Winston Churchill.\n",
      "\n",
      "Q: Who was the next British Prime Minister after Arthur Balf\n",
      "-------------------------\n",
      "Q: Who had a 70s No 1 hit with Kiss You All Over? A:\n",
      "True answer: Exile\n",
      "Model output:  The Beatles\n",
      "\n",
      "The Beatles were the first band to have a No 1 single in the UK, with their cover of Kiss You All Over in 1970.\n",
      "\n",
      "The song was written by Paul McCartney and George Harrison, and was released as a single in the UK on 7 June 1970.\n",
      "\n",
      "It was the first single to be released by the band since their last single, I Want To Hold Your Hand, had been released in March 1969.\n",
      "\n",
      "The song was a huge hit in the UK, reaching No 1 on the UK Singles Chart for three weeks in July 1970.\n",
      "\n",
      "It was also the first single to be released by the band since their last single, I Want To Hold Your Hand, had been released in March 1969.\n",
      "\n",
      "The song was a huge hit in the UK, reaching No 1 on the UK Singles Chart for three weeks in July 1970.\n",
      "\n",
      "It was also the first single to be released by the band since their last single, I Want To Hold Your Hand, had been released in March 1969.\n",
      "\n",
      "The song was a huge hit in the UK, reaching No 1 on the UK Singles Chart for three weeks in\n",
      "-------------------------\n",
      "Q: What claimed the life of singer Kathleen Ferrier? A:\n",
      "True answer: Cancer\n",
      "Model output:  Kathleen Ferrier, a singer and actress, was found dead in her home in Los Angeles on March 1, 2009. She was 46.\n",
      "\n",
      "Q: What was the cause of death? A: Ferrier died of a heart attack.\n",
      "\n",
      "Q: Who was Kathleen Ferrier? A: Ferrier was a singer and actress. She was born Kathleen Ferrier in New York City on July 17, 1964. She was the daughter of actress and singer Kathleen Ferrier and her husband, actor and director Michael Ferrier. Ferrier was a member of the musical group The Ferriers. She was also a singer and actress. Ferrier was married to actor Michael Ferrier from 1991 to 2007. She was the mother of actor and director Michael Ferrier Jr. and actor Michael Ferrier III.\n",
      "\n",
      "Q: What was her career? A: Ferrier was a singer and actress. She was a member of the musical group The Ferriers. She was also a singer and actress. Ferrier was married to actor Michael Ferrier from 1991 to 2007. She was the mother of actor and director Michael Ferrier Jr. and actor Michael Ferrier III.\n",
      "\n",
      "Q: What was\n",
      "-------------------------\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from all the answers being wrong, after the answer, the model continues to either repeat the question/answer or asks new questions. To account for this issue a better prompt format is needed. To account for this issue, the paper (page 16) proposes to trim all generations by pattern matching for the bad-words \"Q:\", \"Question:\", \"QUESTION:\", \"questions:\". This means that those tokens will not be part of the generation. \n",
    "\n",
    "Another problem is that \" Q:\" and \" A:\" are tokenized with a leading space. This leads to the problem that each generation starts with a space and therefore the probability of the sequence is distorted. As [this](https://github.com/meta-llama/llama/issues/217#issuecomment-1774147331) discussion on GitHub proposes, I remove all spaces."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T19:53:44.910966Z",
     "start_time": "2024-06-07T19:53:44.896967Z"
    }
   },
   "source": [
    "print(f\"Tokenization for 'Q:': {tokenizer('Q:')}\\t for ' Q:': {tokenizer(' Q:')}\")\n",
    "print(f\"Tokenization for 'A:': {tokenizer('A:')}\\t for ' A:': {tokenizer(' A:')}\")\n",
    "print()\n",
    "example_answer = \"The Chipmunks Q: Who was the man behind The Chipmunks? A:\"\n",
    "print(f\"Excerpt of example answer{example_answer}\")\n",
    "tokenized_example_answer = tokenizer(example_answer)\n",
    "print(f\"Tokenized example answer: {tokenized_example_answer}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization for 'Q:': {'input_ids': [2, 1864, 35], 'attention_mask': [1, 1, 1]}\t for ' Q:': {'input_ids': [2, 1209, 35], 'attention_mask': [1, 1, 1]}\n",
      "Tokenization for 'A:': {'input_ids': [2, 250, 35], 'attention_mask': [1, 1, 1]}\t for ' A:': {'input_ids': [2, 83, 35], 'attention_mask': [1, 1, 1]}\n",
      "\n",
      "Excerpt of example answerThe Chipmunks Q: Who was the man behind The Chipmunks? A:\n",
      "Tokenized example answer: {'input_ids': [2, 133, 11055, 20614, 2258, 1209, 35, 3394, 21, 5, 313, 639, 20, 11055, 20614, 2258, 116, 83, 35], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "As you can see, the series 1209, 35 and the series 83, 35 appear in the tokenized example answer, but the series 1864, 35 and the series 250, 35 for the token without leading space don't appear. When removing the spaces, the tokenizer has problems in tokenizing \"Q:\" and \"A:\" as one token. As a result, I change them to \"QUESTION:\" and \"ANSWER:\"."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Better prompt format/Changes in generation\n",
    "- QUESTION:, ANSWER: instead of Q:, A:\n",
    "- No empty spaces between QUESTION:, ANSWER:\n",
    "- Paper (page 16): Few-shot prompting with n=10\n",
    "- New line after each sample in few shot prompt \n",
    "- New line character as eos token id (this makes sense as TriviaQA provides short answers in one line) --> Generation stops, once a \\n is encountered\n",
    "- After a lot of tries and evaluating answers: Improved the list of stop tokens\n",
    "- Set maximum token length that generated answer can have to smaller value as answers in TriviaQA are also quite short"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T19:53:44.958654Z",
     "start_time": "2024-06-07T19:53:44.911966Z"
    }
   },
   "source": [
    "# Few shot prompt\n",
    "selected_training_data = data_trivia_train.select(range(0, 10))\n",
    "ten_shot_prompt = \"\"\n",
    "for data in selected_training_data:\n",
    "    ten_shot_prompt += \"QUESTION:\" + data[\"question\"] + \"ANSWER:\" + data[\"answer\"][\"value\"] + \"\\n\"\n",
    "\n",
    "# Define stop tokens, use token on position 1 bc position 0 is special token\n",
    "stop_tokens = [\"Q:\", \"Question:\", \"QUESTION:\", \"questions:\", \" Q:\", \" Question:\", \" QUESTION:\", \" questions:\",\n",
    "               \"A:\", \"Answer:\", \"ANSWER:\", \"answers:\", \" A:\", \" Answer:\", \" ANSWER:\", \" answers:\", \"Answers:\",\n",
    "               \" Answers:\",\n",
    "               \"Topic:\", \" Topic:\", \"TOPIC:\", \" TOPIC:\", \".\", \" .\", \"...\", \" ...\", \"?\", \" ?\", \":\", \" :\", \"!\", \" !\"]\n",
    "stop_tokens = [[tokenizer(stop_token)[\"input_ids\"][1]] for stop_token in stop_tokens]\n",
    "\n",
    "# Define eos token\n",
    "eos_token = tokenizer(\"\\n\")[\"input_ids\"][1]\n",
    "tokenizer.pad_token_id = eos_token\n",
    "tokenizer.eos_token_id = eos_token\n",
    "\n",
    "# Maximum token length that generated answer can have\n",
    "max_new_tokens = 32"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "That means, that the few shot prompt looks like this + \"QUESTION:<question we really want to ask>ANSWER:\". In the following, only the question we really want to ask is printed out."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T19:53:46.400704Z",
     "start_time": "2024-06-07T19:53:46.387706Z"
    }
   },
   "cell_type": "code",
   "source": "print(ten_shot_prompt)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION:Which American-born Sinclair won the Nobel Prize for Literature in 1930?ANSWER:Sinclair Lewis\n",
      "QUESTION:Where in England was Dame Judi Dench born?ANSWER:York\n",
      "QUESTION:In which decade did Billboard magazine first publish and American hit chart?ANSWER:30s\n",
      "QUESTION:From which country did Angola achieve independence in 1975?ANSWER:Portugal\n",
      "QUESTION:Which city does David Soul come from?ANSWER:Chicago\n",
      "QUESTION:Who won Super Bowl XX?ANSWER:Chicago Bears\n",
      "QUESTION:Which was the first European country to abolish capital punishment?ANSWER:Norway\n",
      "QUESTION:In which country did he widespread use of ISDN begin in 1988?ANSWER:Japan\n",
      "QUESTION:What is Bruce Willis' real first name?ANSWER:Walter\n",
      "QUESTION:Which William wrote the novel Lord Of The Flies?ANSWER:Golding\n",
      "\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Try generating sequences again with the new prompt format:"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T19:53:54.161842Z",
     "start_time": "2024-06-07T19:53:52.029504Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(10):\n",
    "    question = ten_shot_prompt + \"QUESTION:\" + data_trivia_val[i][\"question\"] + \"ANSWER:\"\n",
    "    answer = data_trivia_val[i][\"answer\"][\"value\"]\n",
    "\n",
    "    # As mentioned above, only print question\n",
    "    print(f\"Question: {data_trivia_val[i]['question']}\")\n",
    "    print(f\"True Answer: {answer}\")\n",
    "\n",
    "    inputs = tokenizer(question, padding=False, truncation=False, return_tensors=\"pt\").to(device)\n",
    "    length_input = inputs[\"input_ids\"].shape[1]\n",
    "\n",
    "    # Generate sequence by always taking token with max probability (greedy)\n",
    "    output_generate = model.generate(inputs.input_ids,\n",
    "                                     max_new_tokens=max_new_tokens,\n",
    "                                     eos_token_id=eos_token,\n",
    "                                     bad_words_ids=stop_tokens)\n",
    "    output = tokenizer.batch_decode(output_generate[0][length_input:], skip_special_tokens=True)\n",
    "    print(f\"Model Output: {''.join(output)}\")\n",
    "    print(\"-------------------------\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who was the man behind The Chipmunks?\n",
      "True Answer: David Seville\n",
      "Model Output: Walt Disney\n",
      "\n",
      "-------------------------\n",
      "Question: Which Lloyd Webber musical premiered in the US on 10th December 1993?\n",
      "True Answer: Sunset Boulevard\n",
      "Model Output: The Phantom Of The Opera\n",
      "\n",
      "-------------------------\n",
      "Question: Who was the next British Prime Minister after Arthur Balfour?\n",
      "True Answer: Campbell-Bannerman\n",
      "Model Output: John Major\n",
      "\n",
      "-------------------------\n",
      "Question: Who had a 70s No 1 hit with Kiss You All Over?\n",
      "True Answer: Exile\n",
      "Model Output: The Beatles\n",
      "\n",
      "-------------------------\n",
      "Question: What claimed the life of singer Kathleen Ferrier?\n",
      "True Answer: Cancer\n",
      "Model Output: The Beatles\n",
      "\n",
      "-------------------------\n",
      "Question: Rita Coolidge sang the title song for which Bond film?\n",
      "True Answer: Octopussy\n",
      "Model Output: Live And Let Die\n",
      "\n",
      "-------------------------\n",
      "Question: What was the last US state to reintroduce alcohol after prohibition?\n",
      "True Answer: Utah\n",
      "Model Output: New York\n",
      "\n",
      "-------------------------\n",
      "Question: Which actress was voted Miss Greenwich Village in 1942?\n",
      "True Answer: Lauren Bacall\n",
      "Model Output: Betty Grable\n",
      "\n",
      "-------------------------\n",
      "Question: What is the Japanese share index called?\n",
      "True Answer: Nikkei\n",
      "Model Output: The Nikkei\n",
      "\n",
      "-------------------------\n",
      "Question: What was the name of Michael Jackson's autobiography written in 1988?\n",
      "True Answer: Moonwalk\n",
      "Model Output: Billie Jean\n",
      "\n",
      "-------------------------\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The format of the answers looks good - we can argue about their correctness though (except for one example).\n",
    "\n",
    "## Include probability of generated output sequence and number of output tokens\n",
    "Number of output tokens used to calculate length-normalized predictive entropy\n",
    "\n",
    "For calculating the probability of generated output, see: https://discuss.huggingface.co/t/announcement-generation-get-probabilities-for-generated-output/30075\n",
    "\n",
    "The function that calculates the probability of a sequence is implemented in the `utils.py` file. When using the generate method with multiple return sequences the special token <pad> for padding purposes is used. As special tokens should not be included in the calculation of the probability of the output, they are excluded (also in the count of output tokens). Special tokens can be identified by having a < and a >. \n",
    "\n",
    "For example: \n",
    "['D', 'ery', 'ck', ' Gibson', '\\n', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
    "\n",
    "Here, only the first 5 tokens should be included."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T19:56:10.434050Z",
     "start_time": "2024-06-07T19:56:09.362735Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in [100, 200, 300]:\n",
    "    question = ten_shot_prompt + \"QUESTION:\" + data_trivia_val[i][\"question\"] + \"ANSWER:\"\n",
    "    answer = data_trivia_val[i][\"answer\"][\"value\"]\n",
    "\n",
    "    # As mentioned above, only print question\n",
    "    print(f\"Question: {data_trivia_val[i]['question']}\")\n",
    "    print(f\"True Answer: {answer}\")\n",
    "\n",
    "    inputs = tokenizer(question, padding=False, truncation=False, return_tensors=\"pt\").to(device)\n",
    "    length_input = inputs[\"input_ids\"].shape[1]\n",
    "\n",
    "    output_generate = model.generate(inputs.input_ids,\n",
    "                                     max_new_tokens=max_new_tokens,\n",
    "                                     eos_token_id=eos_token,\n",
    "                                     bad_words_ids=stop_tokens,\n",
    "                                     return_dict_in_generate=True,\n",
    "                                     output_scores=True)\n",
    "    output = tokenizer.batch_decode(output_generate.sequences[0][length_input:], skip_special_tokens=True)\n",
    "\n",
    "    # Calculate probability and count output tokens\n",
    "    prob_output, n_output_tokens = calculate_probability_sequence(model, tokenizer, output_generate, length_input,\n",
    "                                                                  print_scores=True)\n",
    "\n",
    "    print(f\"Model Output: {''.join(output)}\")\n",
    "    print(f\"Probability of output: {prob_output}\")\n",
    "    print(f\"Number of output tokens: {n_output_tokens}\")\n",
    "    print(\"-------------------------\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Which Oscar-nominated film had You Sexy Thing as its theme song?\n",
      "True Answer: The Full Monty\n",
      "  133 | 'The'        | -1.9775 | 13.84%\n",
      " 6748 | ' Dep'       | -3.2594 | 3.84%\n",
      "26587 | 'arted'      | -0.0164 | 98.38%\n",
      "50118 | '\\n'         | -0.0608 | 94.10%\n",
      "Model Output: The Departed\n",
      "\n",
      "Probability of output: 0.004921769236503534\n",
      "Number of output tokens: 4\n",
      "-------------------------\n",
      "Question: Who was the first American to travel faster than the speed of sound?\n",
      "True Answer: Chuck Yeager\n",
      "  863 | 'J'          | -3.3494 | 3.51%\n",
      "17773 | 'ules'       | -1.1234 | 32.52%\n",
      " 3060 | ' Ver'       | -0.0153 | 98.48%\n",
      "  858 | 'ne'         | -0.0002 | 99.98%\n",
      "50118 | '\\n'         | -0.0715 | 93.10%\n",
      "Model Output: Jules Verne\n",
      "\n",
      "Probability of output: 0.010463550529798284\n",
      "Number of output tokens: 5\n",
      "-------------------------\n",
      "Question: What is the longest word can be typed using only the top row of letters on a typewriter?\n",
      "True Answer: Typewriter\n",
      "  176 | '2'          | -3.7893 | 2.26%\n",
      "    6 | ','          | -0.4968 | 60.85%\n",
      "  151 | '000'        | -2.2945 | 10.08%\n",
      " 3768 | ' characters' | -1.1986 | 30.16%\n",
      "50118 | '\\n'         | -0.1074 | 89.82%\n",
      "Model Output: 2,000 characters\n",
      "\n",
      "Probability of output: 0.00037576269509422716\n",
      "Number of output tokens: 5\n",
      "-------------------------\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Sampling multiple answers\n",
    "See: https://huggingface.co/docs/transformers/en/generation_strategies and https://huggingface.co/blog/how-to-generate\n",
    "\n",
    "Sample 10 answers per question (see page 8 in paper).\n",
    "\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T20:00:52.888137Z",
     "start_time": "2024-06-07T20:00:52.878137Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# How many questions to test in this jupyter notebook\n",
    "n_questions = 10\n",
    "\n",
    "# How many answers to sample (here 10, see page 8 in paper)\n",
    "n_sample = 10\n",
    "\n",
    "# Temperature for sampling (used in paper: 0.25, 0.5, 1, 1.5)\n",
    "temperature = 0.5"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Multinomial sampling"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T20:04:28.163689Z",
     "start_time": "2024-06-07T20:01:46.225748Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(n_questions):\n",
    "    question = ten_shot_prompt + \"QUESTION:\" + data_trivia_val[i][\"question\"] + \"ANSWER:\"\n",
    "    answer = data_trivia_val[i][\"answer\"][\"value\"]\n",
    "\n",
    "    # As mentioned above, only print question\n",
    "    print(f\"Question: {data_trivia_val[i]['question']}\")\n",
    "    print(f\"True Answer: {answer}\")\n",
    "\n",
    "    inputs = tokenizer(question, padding=False, truncation=False, return_tensors=\"pt\").to(device)\n",
    "    length_input = inputs[\"input_ids\"].shape[1]\n",
    "\n",
    "    # Sample sequences\n",
    "    output_generate = model.generate(inputs.input_ids,\n",
    "                                     max_new_tokens=max_new_tokens,\n",
    "                                     eos_token_id=eos_token,\n",
    "                                     bad_words_ids=stop_tokens,\n",
    "                                     return_dict_in_generate=True,\n",
    "                                     output_scores=True,\n",
    "                                     do_sample=True,\n",
    "                                     num_return_sequences=n_sample,\n",
    "                                     temperature=temperature,\n",
    "                                     top_p=0.9)\n",
    "\n",
    "    for n_sequence in range(n_sample):\n",
    "        output = tokenizer.batch_decode(output_generate.sequences[n_sequence][length_input:],\n",
    "                                        skip_special_tokens=True)\n",
    "\n",
    "        # Calculating probability of sequence\n",
    "        prob_output, n_output_tokens = calculate_probability_sequence(model, tokenizer, output_generate, length_input,\n",
    "                                                                      idx=n_sequence,\n",
    "                                                                      print_scores=False)\n",
    "\n",
    "        # Print out result\n",
    "        output_string = \"\".join(output).replace(\"\\n\", \"\")\n",
    "        print(f\"Sequence ({n_sequence}): {output_string} (P: {prob_output:.6}, Length output: {n_output_tokens})\")\n",
    "    print(\"-------------------------\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who was the man behind The Chipmunks?\n",
      "True Answer: David Seville\n",
      "Sequence (0): Harrison Bergeron (P: 0.00175879, Length output: 5)\n",
      "Sequence (1): Morten (P: 0.00174914, Length output: 4)\n",
      "Sequence (2): Chip (P: 0.0737231, Length output: 2)\n",
      "Sequence (3): Bender (P: 0.00250416, Length output: 3)\n",
      "Sequence (4): Kris Kristofferson (P: 0.00443387, Length output: 6)\n",
      "Sequence (5): Spencer (P: 0.0198019, Length output: 4)\n",
      "Sequence (6): Thomas Middleditch (P: 0.0646235, Length output: 5)\n",
      "Sequence (7): Thomas Middleditch (P: 0.0646235, Length output: 5)\n",
      "Sequence (8): Hoffman (P: 0.007357, Length output: 4)\n",
      "Sequence (9): Steven Spielberg (P: 0.0162728, Length output: 3)\n",
      "-------------------------\n",
      "Question: Which Lloyd Webber musical premiered in the US on 10th December 1993?\n",
      "True Answer: Sunset Boulevard\n",
      "Sequence (0): Les Miserables (P: 0.0623636, Length output: 5)\n",
      "Sequence (1): The Phantom Of The Opera (P: 0.810635, Length output: 6)\n",
      "Sequence (2): The Phantom Of The Opera (P: 0.810635, Length output: 6)\n",
      "Sequence (3): The Phantom Of The Opera (P: 0.810635, Length output: 6)\n",
      "Sequence (4): The Phantom Of The Opera (P: 0.810635, Length output: 6)\n",
      "Sequence (5): The Phantom Of The Opera (P: 0.810635, Length output: 6)\n",
      "Sequence (6): The Phantom Of The Opera (P: 0.810635, Length output: 6)\n",
      "Sequence (7): The Phantom Of The Opera (P: 0.810635, Length output: 6)\n",
      "Sequence (8): The Phantom Of The Opera (P: 0.810635, Length output: 6)\n",
      "Sequence (9): Mamma Mia (P: 0.00851733, Length output: 5)\n",
      "-------------------------\n",
      "Question: Who was the next British Prime Minister after Arthur Balfour?\n",
      "True Answer: Campbell-Bannerman\n",
      "Sequence (0): Margaret Thatcher (P: 0.139595, Length output: 4)\n",
      "Sequence (1): William Ewart Gladstone (P: 0.0261034, Length output: 6)\n",
      "Sequence (2): John Major (P: 0.210629, Length output: 3)\n",
      "Sequence (3): John Major (P: 0.210629, Length output: 3)\n",
      "Sequence (4): John Major (P: 0.210629, Length output: 3)\n",
      "Sequence (5): Margaret Thatcher (P: 0.139595, Length output: 4)\n",
      "Sequence (6): David Lloyd George (P: 0.207048, Length output: 4)\n",
      "Sequence (7): David Lloyd George (P: 0.207048, Length output: 4)\n",
      "Sequence (8): William Gladstone (P: 0.0512594, Length output: 4)\n",
      "Sequence (9): John Major (P: 0.210629, Length output: 3)\n",
      "-------------------------\n",
      "Question: Who had a 70s No 1 hit with Kiss You All Over?\n",
      "True Answer: Exile\n",
      "Sequence (0): Kiss You All Over (P: 0.016606, Length output: 6)\n",
      "Sequence (1): The Police (P: 0.119976, Length output: 3)\n",
      "Sequence (2): Dennis DeYoung (P: 0.000872918, Length output: 5)\n",
      "Sequence (3): The Beatles (P: 0.250055, Length output: 3)\n",
      "Sequence (4): Kiss (P: 0.0558025, Length output: 3)\n",
      "Sequence (5): Bobby Brown (P: 0.0332698, Length output: 4)\n",
      "Sequence (6): The Police (P: 0.119976, Length output: 3)\n",
      "Sequence (7): Billy Joel (P: 0.0114047, Length output: 3)\n",
      "Sequence (8): The Bee Gees (P: 0.055419, Length output: 5)\n",
      "Sequence (9): Cher (P: 0.0234743, Length output: 3)\n",
      "-------------------------\n",
      "Question: What claimed the life of singer Kathleen Ferrier?\n",
      "True Answer: Cancer\n",
      "Sequence (0): Kathleen Ferrier (P: 0.121641, Length output: 6)\n",
      "Sequence (1): Husband (P: 0.00731582, Length output: 4)\n",
      "Sequence (2): Kathleen Ferrier (P: 0.121641, Length output: 6)\n",
      "Sequence (3): Her husband (P: 0.121648, Length output: 3)\n",
      "Sequence (4): Kathleen Ferrier (P: 0.121641, Length output: 6)\n",
      "Sequence (5): Husband (P: 0.00731582, Length output: 4)\n",
      "Sequence (6): Suicide (P: 0.105157, Length output: 3)\n",
      "Sequence (7): Her husband (P: 0.121648, Length output: 3)\n",
      "Sequence (8): Kathleen Ferrier (P: 0.121641, Length output: 6)\n",
      "Sequence (9): Kathleen Ferrier (P: 0.121641, Length output: 6)\n",
      "-------------------------\n",
      "Question: Rita Coolidge sang the title song for which Bond film?\n",
      "True Answer: Octopussy\n",
      "Sequence (0): Moonraker (P: 0.188107, Length output: 4)\n",
      "Sequence (1): Goldfinger (P: 0.216991, Length output: 3)\n",
      "Sequence (2): Live And Let Die (P: 0.231547, Length output: 5)\n",
      "Sequence (3): Casino Royale (P: 0.0731111, Length output: 4)\n",
      "Sequence (4): Live And Let Die (P: 0.231547, Length output: 5)\n",
      "Sequence (5): Goldfinger (P: 0.216991, Length output: 3)\n",
      "Sequence (6): Goldfinger (P: 0.216991, Length output: 3)\n",
      "Sequence (7): Live And Let Die (P: 0.231547, Length output: 5)\n",
      "Sequence (8): Goldfinger (P: 0.216991, Length output: 3)\n",
      "Sequence (9): Goldfinger (P: 0.216991, Length output: 3)\n",
      "-------------------------\n",
      "Question: What was the last US state to reintroduce alcohol after prohibition?\n",
      "True Answer: Utah\n",
      "Sequence (0): California (P: 0.0740538, Length output: 2)\n",
      "Sequence (1): Mississippi (P: 0.107083, Length output: 4)\n",
      "Sequence (2): New Hampshire (P: 0.0595788, Length output: 3)\n",
      "Sequence (3): Nevada (P: 0.0415116, Length output: 3)\n",
      "Sequence (4): Mississippi (P: 0.107083, Length output: 4)\n",
      "Sequence (5): Mississippi (P: 0.107083, Length output: 4)\n",
      "Sequence (6): New York (P: 0.131323, Length output: 3)\n",
      "Sequence (7): California (P: 0.0740538, Length output: 2)\n",
      "Sequence (8): Alaska (P: 0.199233, Length output: 3)\n",
      "Sequence (9): Mississippi (P: 0.107083, Length output: 4)\n",
      "-------------------------\n",
      "Question: Which actress was voted Miss Greenwich Village in 1942?\n",
      "True Answer: Lauren Bacall\n",
      "Sequence (0): Betty Grable (P: 0.15468, Length output: 5)\n",
      "Sequence (1): Audrey Hepburn (P: 0.0315562, Length output: 5)\n",
      "Sequence (2): Betty Grable (P: 0.15468, Length output: 5)\n",
      "Sequence (3): Ginger Rogers (P: 0.0111811, Length output: 4)\n",
      "Sequence (4): Mary Pickford (P: 0.0285197, Length output: 4)\n",
      "Sequence (5): Bette Davis (P: 0.039632, Length output: 4)\n",
      "Sequence (6): Sally Field (P: 0.033742, Length output: 4)\n",
      "Sequence (7): Bette Davis (P: 0.039632, Length output: 4)\n",
      "Sequence (8): Betty Grable (P: 0.15468, Length output: 5)\n",
      "Sequence (9): Audrey Hepburn (P: 0.0315562, Length output: 5)\n",
      "-------------------------\n",
      "Question: What is the Japanese share index called?\n",
      "True Answer: Nikkei\n",
      "Sequence (0): The Nikkei (P: 0.341927, Length output: 5)\n",
      "Sequence (1): The Nikkei (P: 0.341927, Length output: 5)\n",
      "Sequence (2): The Nikkei (P: 0.341927, Length output: 5)\n",
      "Sequence (3): The Nikkei (P: 0.341927, Length output: 5)\n",
      "Sequence (4): The Nikkei (P: 0.341927, Length output: 5)\n",
      "Sequence (5): Nikkei (P: 0.223757, Length output: 4)\n",
      "Sequence (6): Nikkei (P: 0.223757, Length output: 4)\n",
      "Sequence (7): Nikkei 225 (P: 0.210093, Length output: 5)\n",
      "Sequence (8): The Nikkei (P: 0.341927, Length output: 5)\n",
      "Sequence (9): Nikkei (P: 0.223757, Length output: 4)\n",
      "-------------------------\n",
      "Question: What was the name of Michael Jackson's autobiography written in 1988?\n",
      "True Answer: Moonwalk\n",
      "Sequence (0): The Man Who Would Be King (P: 0.00291251, Length output: 7)\n",
      "Sequence (1): Billie Jean (P: 0.3261, Length output: 4)\n",
      "Sequence (2): Thriller (P: 0.342185, Length output: 4)\n",
      "Sequence (3): Bad (P: 0.114491, Length output: 2)\n",
      "Sequence (4): Billie Jean (P: 0.3261, Length output: 4)\n",
      "Sequence (5): Billboard (P: 0.0419685, Length output: 3)\n",
      "Sequence (6): Billie Jean (P: 0.3261, Length output: 4)\n",
      "Sequence (7): Billboard (P: 0.0419685, Length output: 3)\n",
      "Sequence (8): Thriller (P: 0.342185, Length output: 4)\n",
      "Sequence (9): Bad (P: 0.114491, Length output: 2)\n",
      "-------------------------\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Multinomial Beam Sampling\n",
    "n_sample highest scoring beams are returned"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T20:32:56.781919Z",
     "start_time": "2024-06-07T20:05:29.551439Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(n_questions):\n",
    "    question = ten_shot_prompt + \"QUESTION:\" + data_trivia_val[i][\"question\"] + \"ANSWER:\"\n",
    "    answer = data_trivia_val[i][\"answer\"][\"value\"]\n",
    "\n",
    "    # As mentioned above, only print question\n",
    "    print(f\"Question: {data_trivia_val[i]['question']}\")\n",
    "    print(f\"True Answer: {answer}\")\n",
    "\n",
    "    inputs = tokenizer(question, padding=False, truncation=False, return_tensors=\"pt\").to(device)\n",
    "    length_input = inputs[\"input_ids\"].shape[1]\n",
    "\n",
    "    # Sample sequences\n",
    "    output_generate = model.generate(inputs.input_ids,\n",
    "                                     max_new_tokens=max_new_tokens,\n",
    "                                     eos_token_id=eos_token,\n",
    "                                     bad_words_ids=stop_tokens,\n",
    "                                     return_dict_in_generate=True,\n",
    "                                     output_scores=True,\n",
    "                                     do_sample=True,\n",
    "                                     num_beams=2 * n_sample,\n",
    "                                     num_return_sequences=n_sample)\n",
    "\n",
    "    for n_sequence in range(n_sample):\n",
    "        output = tokenizer.batch_decode(output_generate.sequences[n_sequence][length_input:],\n",
    "                                        skip_special_tokens=True)\n",
    "\n",
    "        # Calculating probability of sequence\n",
    "        prob_output, n_output_tokens = calculate_probability_sequence(model, tokenizer, output_generate, length_input,\n",
    "                                                                      beam_sampling=True,\n",
    "                                                                      idx=n_sequence,\n",
    "                                                                      print_scores=False)\n",
    "\n",
    "        # Print out result\n",
    "        output_string = ''.join(output).replace(\"\\n\", \"\")\n",
    "        print(f\"Sequence ({n_sequence}): {output_string} (P: {prob_output:.6}, Length output: {n_output_tokens})\")\n",
    "    print(\"-------------------------\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who was the man behind The Chipmunks?\n",
      "True Answer: David Seville\n",
      "Sequence (0): Werner HerzogI don't know if this is the right place to post this, but I was wondering if anyone would be able to help me (P: 4.54025e-15, Length output: 31)\n",
      "Sequence (1): Werner Herzog (P: 0.00127962, Length output: 6)\n",
      "Sequence (2): Werner Herzog (P: 0.00127962, Length output: 6)\n",
      "Sequence (3): Werner HerzogI don't know if this is the right place to post this, but I was wondering if anyone would be able to tell me (P: 2.35571e-15, Length output: 31)\n",
      "Sequence (4): Wyatt Earp (P: 0.00163115, Length output: 6)\n",
      "Sequence (5): Werner HerzogI don't know if this is the right place to post this, but I was wondering if anyone could help me out with a (P: 4.927e-15, Length output: 31)\n",
      "Sequence (6): Werner HerzogI don't know if this is the right place to ask this, but does anyone know where I can get a copy of the (P: 4.18717e-15, Length output: 31)\n",
      "Sequence (7): Thomas Middleditch (P: 0.00711988, Length output: 5)\n",
      "Sequence (8): Walt Disney (P: 0.0138938, Length output: 4)\n",
      "Sequence (9): Walt Disney (P: 0.0138938, Length output: 4)\n",
      "-------------------------\n",
      "Question: Which Lloyd Webber musical premiered in the US on 10th December 1993?\n",
      "True Answer: Sunset Boulevard\n",
      "Sequence (0): The Phantom Of The Opera (P: 0.0887935, Length output: 6)\n",
      "Sequence (1): The Phantom Of The Opera (P: 0.0887935, Length output: 6)\n",
      "Sequence (2): The Phantom Of The Opera (P: 0.0887935, Length output: 6)\n",
      "Sequence (3): The Phantom Of The Opera (P: 0.0887935, Length output: 6)\n",
      "Sequence (4): The Phantom Of The Opera (P: 0.0887935, Length output: 6)\n",
      "Sequence (5): The Phantom Of The Opera (P: 0.0887935, Length output: 6)\n",
      "Sequence (6): Les Miserables (P: 0.0436758, Length output: 5)\n",
      "Sequence (7): Les Miserables (P: 0.0436758, Length output: 5)\n",
      "Sequence (8): Les Miserables (P: 0.0436758, Length output: 5)\n",
      "Sequence (9): Les Misérables (P: 0.0250159, Length output: 5)\n",
      "-------------------------\n",
      "Question: Who was the next British Prime Minister after Arthur Balfour?\n",
      "True Answer: Campbell-Bannerman\n",
      "Sequence (0): Margaret Thatcher (P: 0.0668388, Length output: 4)\n",
      "Sequence (1): Margaret Thatcher (P: 0.0668388, Length output: 4)\n",
      "Sequence (2): Margaret Thatcher (P: 0.0668388, Length output: 4)\n",
      "Sequence (3): Margaret Thatcher (P: 0.0668388, Length output: 4)\n",
      "Sequence (4): Winston Churchill (P: 0.054461, Length output: 4)\n",
      "Sequence (5): Winston Churchill (P: 0.054461, Length output: 4)\n",
      "Sequence (6): Winston Churchill (P: 0.054461, Length output: 4)\n",
      "Sequence (7): Winston Churchill (P: 0.054461, Length output: 4)\n",
      "Sequence (8): David Lloyd George (P: 0.0510328, Length output: 4)\n",
      "Sequence (9): David Lloyd George (P: 0.0510328, Length output: 4)\n",
      "-------------------------\n",
      "Question: Who had a 70s No 1 hit with Kiss You All Over?\n",
      "True Answer: Exile\n",
      "Sequence (0): Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss (P: 2.48569e-06, Length output: 32)\n",
      "Sequence (1): Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss (P: 2.48569e-06, Length output: 32)\n",
      "Sequence (2): Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss (P: 2.48569e-06, Length output: 32)\n",
      "Sequence (3): Kiss You All Over, Kiss You All Over, Kiss You All Over, Kiss You All Over, Kiss You All Over, Kiss You All Over, Kiss (P: 1.05703e-06, Length output: 32)\n",
      "Sequence (4): Kiss You All Over, Kiss You All Over, Kiss You All Over, Kiss You All Over, Kiss You All Over, Kiss You All Over (P: 5.94465e-07, Length output: 31)\n",
      "Sequence (5): Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me (P: 2.97457e-07, Length output: 31)\n",
      "Sequence (6): Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me (P: 2.97457e-07, Length output: 31)\n",
      "Sequence (7): Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me (P: 2.97457e-07, Length output: 31)\n",
      "Sequence (8): Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me (P: 4.63043e-07, Length output: 28)\n",
      "Sequence (9): Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me (P: 4.63043e-07, Length output: 28)\n",
      "-------------------------\n",
      "Question: What claimed the life of singer Kathleen Ferrier?\n",
      "True Answer: Cancer\n",
      "Sequence (0): Kathleen Ferrier (P: 0.0213919, Length output: 6)\n",
      "Sequence (1): Kathleen Ferrier (P: 0.0213919, Length output: 6)\n",
      "Sequence (2): Singer Kathleen Ferrier (P: 0.0133871, Length output: 6)\n",
      "Sequence (3): Singer Kathleen Ferrier (P: 0.0133871, Length output: 6)\n",
      "Sequence (4): Singer Kathleen Ferrier (P: 0.0133871, Length output: 6)\n",
      "Sequence (5): Kathleen Ferrier was killed by a hit-and-run driver (P: 1.83352e-07, Length output: 16)\n",
      "Sequence (6): Kathleen Ferrier was killed by a hit-and-run driver in New York City (P: 1.54636e-09, Length output: 20)\n",
      "Sequence (7): Kathleen Ferrier was killed by a hit-and-run driver while riding her bicycle (P: 5.84762e-10, Length output: 20)\n",
      "Sequence (8): Kathleen Ferrier was killed by a hit-and-run driver while crossing the street (P: 6.52777e-10, Length output: 20)\n",
      "Sequence (9): Kathleen Ferrier was killed by a hit-and-run driver in 1991 (P: 6.78607e-09, Length output: 18)\n",
      "-------------------------\n",
      "Question: Rita Coolidge sang the title song for which Bond film?\n",
      "True Answer: Octopussy\n",
      "Sequence (0): Live And Let Die (P: 0.0737668, Length output: 5)\n",
      "Sequence (1): Live And Let Die (P: 0.0737668, Length output: 5)\n",
      "Sequence (2): Live And Let Die (P: 0.0737668, Length output: 5)\n",
      "Sequence (3): Live And Let Die (P: 0.0737668, Length output: 5)\n",
      "Sequence (4): Moonraker (P: 0.094518, Length output: 4)\n",
      "Sequence (5): Moonraker (P: 0.094518, Length output: 4)\n",
      "Sequence (6): Moonraker (P: 0.094518, Length output: 4)\n",
      "Sequence (7): Moonraker (P: 0.094518, Length output: 4)\n",
      "Sequence (8): Casino Royale (P: 0.0577001, Length output: 4)\n",
      "Sequence (9): Casino Royale (P: 0.0577001, Length output: 4)\n",
      "-------------------------\n",
      "Question: What was the last US state to reintroduce alcohol after prohibition?\n",
      "True Answer: Utah\n",
      "Sequence (0): Mississippi (P: 0.0433697, Length output: 4)\n",
      "Sequence (1): Mississippi (P: 0.0433697, Length output: 4)\n",
      "Sequence (2): Alaska (P: 0.0833051, Length output: 3)\n",
      "Sequence (3): Alaska (P: 0.0833051, Length output: 3)\n",
      "Sequence (4): Alaska (P: 0.0833051, Length output: 3)\n",
      "Sequence (5): Nevada (P: 0.038627, Length output: 3)\n",
      "Sequence (6): Nevada (P: 0.038627, Length output: 3)\n",
      "Sequence (7): Nevada (P: 0.038627, Length output: 3)\n",
      "Sequence (8): New York (P: 0.0346442, Length output: 3)\n",
      "Sequence (9): New York (P: 0.0346442, Length output: 3)\n",
      "-------------------------\n",
      "Question: Which actress was voted Miss Greenwich Village in 1942?\n",
      "True Answer: Lauren Bacall\n",
      "Sequence (0): Betty Grable (P: 0.0361214, Length output: 5)\n",
      "Sequence (1): Betty Grable (P: 0.0361214, Length output: 5)\n",
      "Sequence (2): Betty Grable (P: 0.0361214, Length output: 5)\n",
      "Sequence (3): Audrey Hepburn (P: 0.0259566, Length output: 5)\n",
      "Sequence (4): Dorothy Dandridge (P: 0.00401218, Length output: 7)\n",
      "Sequence (5): Dorothy Dandridge (P: 0.00401218, Length output: 7)\n",
      "Sequence (6): Marilyn Monroe (P: 0.00901621, Length output: 5)\n",
      "Sequence (7): Marilyn Monroe (P: 0.00901621, Length output: 5)\n",
      "Sequence (8): Judy Garland (P: 0.0227527, Length output: 4)\n",
      "Sequence (9): Judy Garland (P: 0.0227527, Length output: 4)\n",
      "-------------------------\n",
      "Question: What is the Japanese share index called?\n",
      "True Answer: Nikkei\n",
      "Sequence (0): Nikkei 225 (P: 0.0870008, Length output: 5)\n",
      "Sequence (1): Nikkei 225 (P: 0.0870008, Length output: 5)\n",
      "Sequence (2): Nikkei 225 (P: 0.0870008, Length output: 5)\n",
      "Sequence (3): Nikkei 225 (P: 0.0870008, Length output: 5)\n",
      "Sequence (4): Nikkei 225 (P: 0.0870008, Length output: 5)\n",
      "Sequence (5): Nikkei 225 (P: 0.0870008, Length output: 5)\n",
      "Sequence (6): Nikkei 225 (P: 0.0870008, Length output: 5)\n",
      "Sequence (7): Nikkei 225 (P: 0.0870008, Length output: 5)\n",
      "Sequence (8): The Nikkei (P: 0.0825726, Length output: 5)\n",
      "Sequence (9): The Nikkei (P: 0.0825726, Length output: 5)\n",
      "-------------------------\n",
      "Question: What was the name of Michael Jackson's autobiography written in 1988?\n",
      "True Answer: Moonwalk\n",
      "Sequence (0): Thriller (P: 0.137927, Length output: 4)\n",
      "Sequence (1): Thriller (P: 0.137927, Length output: 4)\n",
      "Sequence (2): Thriller (P: 0.137927, Length output: 4)\n",
      "Sequence (3): Thriller (P: 0.137927, Length output: 4)\n",
      "Sequence (4): Thriller (P: 0.137927, Length output: 4)\n",
      "Sequence (5): Billie Jean (P: 0.0707904, Length output: 4)\n",
      "Sequence (6): Billie Jean (P: 0.0707904, Length output: 4)\n",
      "Sequence (7): Billie Jean (P: 0.0707904, Length output: 4)\n",
      "Sequence (8): Billie Jean (P: 0.0707904, Length output: 4)\n",
      "Sequence (9): Billie Jean (P: 0.0707904, Length output: 4)\n",
      "-------------------------\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Overall, the quality of generations with beam search looks worse than the one for multimodal sampling. This has mainly three reasons:\n",
    "1) Beam search suffers from repetitive generation. This could be solve by setting no_repeat_ngram_size and early_stopping, however sometimes repetition is desirable \n",
    "2) The generations are longer than the ones for multimodal sampling, however the true answers of the TriviaQA dataset are quite short. \n",
    "3) The generations with beam search seem less diverse. This is also noted in the paper (page 15) and will be visualized later by calculating the diversity scores.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Save generations\n",
    "To not have to run the generation of sequences every time, I save the generations. There are "
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T20:34:16.352645Z",
     "start_time": "2024-06-07T20:34:16.314446Z"
    }
   },
   "cell_type": "code",
   "source": "len(data_trivia_val)",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17944"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "number of samples (=questions with sample answers) in the validation set. For measuring the uncertainty, diversity of generations, ... I don't use the whole validation set due to computational limitations, but will randomly sample 5 groups à 500 samples and then report the mean, SD across those groups."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T20:34:21.013799Z",
     "start_time": "2024-06-07T20:34:21.000749Z"
    }
   },
   "cell_type": "code",
   "source": "import os",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T20:34:25.759284Z",
     "start_time": "2024-06-07T20:34:25.729288Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n_samples_per_group = 500\n",
    "n_groups = 5\n",
    "\n",
    "if not os.path.exists(\"sampled_sequences/group_indices.txt\"):\n",
    "    with open(\"sampled_sequences/group_indices.txt\", \"w\") as f:\n",
    "        for _ in range(n_groups):\n",
    "            sampled_indices = np.random.randint(0, len(data_trivia_val), n_samples_per_group)\n",
    "            f.write(\",\".join([str(i) for i in sampled_indices]) + \"\\n\")"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Per group, a pickle file containing a dict with the following structure should be created:\n",
    "\n",
    "**For multinomial sampling:**\n",
    "```python \n",
    "{ 1131: {\"question\": ..., \n",
    "         \"true_answer\": ..., \n",
    "         \"temperature_0.25\": {\"answers\": [...], \"probabilities\": [...], \"length_output\": [...]},\n",
    "         \"temperature_0.5\": {\"answers\": [...], \"probabilities\": [...], \"length_output\": [...]},\n",
    "         \"temperature_1\": {\"answers\": [...], \"probabilities\": [...], \"length_output\": [...]},\n",
    "         \"temperature_1.5\": {\"answers\": [...], \"probabilities\": [...], \"length_output\": [...]}\n",
    "        }, \n",
    "  4295: ...\n",
    "}\n",
    "```\n",
    "\n",
    "**For multinomial beam sampling:**\n",
    "```python \n",
    "{ 1131: {\"question\": ..., \n",
    "         \"true_answer\": ..., \n",
    "         \"beam_20\": {\"answers\": [...], \"probabilities\": [...], \"length_output\": [...]}\n",
    "        }, \n",
    "  4295: ...\n",
    "}\n",
    "```\n",
    "whereby 1131, 4295 are indices belonging to the group. In the following the created pickle file is visualized to see that the structure is correct, the full code of how to create it can be found in the file `save_generations.py`.\n",
    "\n",
    "(Maybe later on for multinomial beam sampling different number of beams are tried out, that's why it is saved like this)."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T10:04:25.679100Z",
     "start_time": "2024-06-08T10:04:25.592094Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "with open(\"sampled_sequences/multinomial_sampling/group0.pkl\", \"rb\") as f:\n",
    "    content = pickle.load(f)\n",
    "print(content)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{12541: {'question': \"Abraham Maslow's 'Hierarchy of Needs' theory explains?\", 'true_answer': 'Motivation', 'temperature_0.25': {'answers': ['The need for self-actualization\\n', 'The need for self-actualization\\n', 'Hierarchy of Needs\\n', 'The need for self-esteem, self-actualization, and self-actualization\\n', 'The need for self-actualization\\n', 'The need for self-actualization\\n', 'Hierarchy of Needs\\n', 'The need for self-esteem, self-actualization, self-reliance, self-esteem, self-actualization, self-esteem, self-', 'The need for self-actualization\\n', 'The need for self-actualization\\n'], 'probabilities': [0.678553236435347, 0.678553236435347, 0.11729502165704453, 0.02018552522669472, 0.678553236435347, 0.678553236435347, 0.11729502165704453, 0.003271788409672518, 0.678553236435347, 0.678553236435347], 'length_sequences': [8, 8, 6, 18, 8, 8, 6, 32, 8, 8]}, 'temperature_0.5': {'answers': ['Needs, needs, needs, needs, needs, needs, needs, needs, needs, needs, needs, needs, needs, needs, needs, needs', 'The need for self-actualization\\n', '1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,', 'Theory\\n', 'Hierarchy of needs\\n', 'Hierarchy of needs\\n', 'Theory of needs\\n', 'the need for a sense of self\\n', 'Theory\\n', 'Hierarchy of needs\\n'], 'probabilities': [0.001365942183438095, 0.11226149312172223, 0.0004373127875732753, 0.03535353830001536, 0.10162696341316035, 0.10162696341316035, 0.02570080460562516, 0.0005411930041946156, 0.03535353830001536, 0.10162696341316035], 'length_sequences': [32, 8, 32, 3, 6, 6, 5, 8, 3, 6]}, 'temperature_1': {'answers': ['Desire for self-actualization and survival\\n', 'Self-actualization\\n', 'Hierarchy of Needs\\n', \"The 'Needs' of a person are self-actualization and satisfaction\\n\", 'It can be done by both male and female children\\n', 'Human need is the prime motivator for our behavior\\n', 'Hierarchy of needs\\n', 'that every human being needs emotional, moral, psychological and spiritual needs in order to function as a human being\\n', 'The four basic needs (health, wealth, status, esteem) are all based on emotion\\n', 'Hierarchy of Needs\\n'], 'probabilities': [5.4239242817197957e-08, 0.02358510903214864, 0.05471606526893131, 3.4896588890484515e-12, 1.7154257531119098e-13, 6.978580545076583e-09, 0.04218372667302034, 2.662099190506326e-16, 1.4365756615470654e-17, 0.05471606526893131], 'length_sequences': [10, 5, 6, 16, 11, 11, 6, 22, 19, 6]}, 'temperature_1.5': {'answers': ['Empathy\\n', 'Food, water and shelter\\n', 'Self actualization/needs = self actualization/security\\n', 'the four pillars\\n', \"Basic emotionalityI just don't like having so many of the same champions that only appear in a handful (or more rarely a whole team)  Not\", 'Abbott, Heckscher\\n', 'Desire/Nihilism\\n', 'Psychological needs, which include emotional\\n', 'Duty/Love/Emotion/Pride\\n', \"Abraham Maslow's 'Perennial Man'\\n\"], 'probabilities': [0.00031039781260516845, 2.083554308536639e-05, 7.488793621437473e-14, 1.6565897907118706e-06, 3.3653500003733647e-40, 7.996746189541349e-10, 4.101888831342812e-08, 2.0096512493644014e-09, 2.931780861831042e-11, 1.1032881738735488e-09], 'length_sequences': [4, 6, 12, 4, 31, 7, 7, 8, 11, 12]}}}\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
