{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate answers with TriviaQA\n",
    "Used for closed-book QA (=without supporting paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T16:05:04.051964Z",
     "start_time": "2024-06-07T16:05:00.711445Z"
    }
   },
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "from transformers import AutoTokenizer, OPTForCausalLM\n",
    "import numpy as np\n",
    "\n",
    "torch.cuda.empty_cache()"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T16:05:05.488756Z",
     "start_time": "2024-06-07T16:05:05.474750Z"
    }
   },
   "source": "data_dir = \"data\"",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Load and inspect data"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T16:05:19.409634Z",
     "start_time": "2024-06-07T16:05:06.932329Z"
    }
   },
   "source": [
    "data_trivia = load_dataset(\"trivia_qa\", \"rc.nocontext\")\n",
    "\n",
    "# Remove unnecessary columns\n",
    "data_trivia = data_trivia.remove_columns([\"question_source\", \"entity_pages\", \"search_results\"])\n",
    "\n",
    "# Split to train, validation, test set\n",
    "data_trivia_train = data_trivia[\"train\"]\n",
    "data_trivia_val = data_trivia[\"validation\"]\n",
    "data_trivia_test = data_trivia[\"test\"]\n",
    "\n",
    "print(f\"Trivia QA Training Set Size: {data_trivia_train.shape}\")\n",
    "print(f\"Trivia QA Validation Set Size: {data_trivia_val.shape}\")\n",
    "print(f\"Trivia QA Test Set Size: {data_trivia_test.shape}\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Resolving data files:   0%|          | 0/26 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e125a40230714f83b15c82843c9e1ea3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trivia QA Training Set Size: (138384, 3)\n",
      "Trivia QA Validation Set Size: (17944, 3)\n",
      "Trivia QA Test Set Size: (17210, 3)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T12:51:40.053697Z",
     "start_time": "2024-06-07T12:51:40.039718Z"
    }
   },
   "source": [
    "print(\"Training Set\")\n",
    "for i in range(2):\n",
    "    print(f\"Q: {data_trivia_train[i]['question']}\\nA: {data_trivia_train[i]['answer']['value']}\\n\")\n",
    "\n",
    "print(\"Validation Set\")\n",
    "for i in range(2):\n",
    "    print(f\"Q: {data_trivia_val[i]['question']}\\nA: {data_trivia_val[i]['answer']['value']}\\n\")\n",
    "\n",
    "print(\"Test Set\")\n",
    "for i in range(2):\n",
    "    print(f\"Q: {data_trivia_test[i]['question']}\\nA: {data_trivia_test[i]['answer']['value']}\\n\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set\n",
      "Q: Which American-born Sinclair won the Nobel Prize for Literature in 1930?\n",
      "A: Sinclair Lewis\n",
      "\n",
      "Q: Where in England was Dame Judi Dench born?\n",
      "A: York\n",
      "\n",
      "Validation Set\n",
      "Q: Who was the man behind The Chipmunks?\n",
      "A: David Seville\n",
      "\n",
      "Q: Which Lloyd Webber musical premiered in the US on 10th December 1993?\n",
      "A: Sunset Boulevard\n",
      "\n",
      "Test Set\n",
      "Q: Asmara international airport is in which country?\n",
      "A: <unk>\n",
      "\n",
      "Q: At whose concert were 11 people trampled to death in Ohio in 1979?\n",
      "A: <unk>\n",
      "\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Training set: Used for few shot prompt\n",
    "- Validation set: Estimate uncertainty of model\n",
    "\n",
    "Reason: Later evaluate how good uncertainty measure is by using AUROC --> Need correct answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run some predictions\n",
    "Same as in the paper, the OPT model is used. Because of computational constraints, I use the OPT model with 1.3B parameters. The smallest model used in the paper is the one with 2.7B parameters (see page 7)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T16:05:19.503763Z",
     "start_time": "2024-06-07T16:05:19.411634Z"
    }
   },
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T16:06:20.870055Z",
     "start_time": "2024-06-07T16:05:19.504762Z"
    }
   },
   "source": [
    "# Causal LM: model predicts next token \n",
    "checkpoint = \"opt-1.3B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(f\"facebook/{checkpoint}\", cache_dir=data_dir)\n",
    "model = OPTForCausalLM.from_pretrained(f\"facebook/{checkpoint}\", cache_dir=data_dir)\n",
    "model = model.to(device)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joshu\\anaconda3\\envs\\practicalwork\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T12:54:28.369936Z",
     "start_time": "2024-06-07T12:53:49.638193Z"
    }
   },
   "source": [
    "# Try out examples\n",
    "for i in range(5):\n",
    "    question = \"Q: \" + data_trivia_val[i][\"question\"] + \" A:\"\n",
    "    answer = data_trivia_val[i][\"answer\"][\"value\"]\n",
    "\n",
    "    inputs = tokenizer(question, padding=False, truncation=False, return_tensors=\"pt\").to(device)\n",
    "    length_input = inputs[\"input_ids\"].shape[1]\n",
    "\n",
    "    generate_ids = model.generate(inputs.input_ids, max_length=256)\n",
    "    # Only decode answer and not posed question\n",
    "    output = tokenizer.batch_decode(generate_ids[0][length_input:], skip_special_tokens=True)\n",
    "\n",
    "    print(question)\n",
    "    print(f\"True answer: {answer}\")\n",
    "    print(f\"Model output: {''.join(output)}\")\n",
    "    print(\"-------------------------\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Who was the man behind The Chipmunks? A:\n",
      "True answer: David Seville\n",
      "Model output:  The man behind The Chipmunks was a man named Chip.\n",
      "\n",
      "Q: Who was the man behind The Chipmunks? A: The man behind The Chipmunks was a man named Chip.\n",
      "\n",
      "Q: Who was the man behind The Chipmunks? A: The man behind The Chipmunks was a man named Chip.\n",
      "\n",
      "Q: Who was the man behind The Chipmunks? A: The man behind The Chipmunks was a man named Chip.\n",
      "\n",
      "Q: Who was the man behind The Chipmunks? A: The man behind The Chipmunks was a man named Chip.\n",
      "\n",
      "Q: Who was the man behind The Chipmunks? A: The man behind The Chipmunks was a man named Chip.\n",
      "\n",
      "Q: Who was the man behind The Chipmunks? A: The man behind The Chipmunks was a man named Chip.\n",
      "\n",
      "Q: Who was the man behind The Chipmunks? A: The man behind The Chipmunks was a man named Chip.\n",
      "\n",
      "Q: Who was the man behind The Chipmunks? A: The man behind The Chipmunks was a\n",
      "-------------------------\n",
      "Q: Which Lloyd Webber musical premiered in the US on 10th December 1993? A:\n",
      "True answer: Sunset Boulevard\n",
      "Model output:  The Phantom of the Opera\n",
      "\n",
      "Q: Which Lloyd Webber musical premiered in the US on 10th December 1993? A: The Phantom of the Opera\n",
      "\n",
      "Q: Which Lloyd Webber musical premiered in the US on 10th December 1993? A: The Phantom of the Opera\n",
      "\n",
      "Q: Which Lloyd Webber musical premiered in the US on 10th December 1993? A: The Phantom of the Opera\n",
      "\n",
      "Q: Which Lloyd Webber musical premiered in the US on 10th December 1993? A: The Phantom of the Opera\n",
      "\n",
      "Q: Which Lloyd Webber musical premiered in the US on 10th December 1993? A: The Phantom of the Opera\n",
      "\n",
      "Q: Which Lloyd Webber musical premiered in the US on 10th December 1993? A: The Phantom of the Opera\n",
      "\n",
      "Q: Which Lloyd Webber musical premiered in the US on 10th December 1993? A: The Phantom of the Opera\n",
      "\n",
      "Q: Which Lloyd Webber musical premiered in the US on 10th December 1993? A: The Phantom of the Opera\n",
      "\n",
      "Q: Which Lloyd Webber musical premiered in the US on 10th December 1993? A: The Phantom\n",
      "-------------------------\n",
      "Q: Who was the next British Prime Minister after Arthur Balfour? A:\n",
      "True answer: Campbell-Bannerman\n",
      "Model output:  Winston Churchill.\n",
      "\n",
      "Q: Who was the next British Prime Minister after Arthur Balfour? A: Winston Churchill.\n",
      "\n",
      "Q: Who was the next British Prime Minister after Arthur Balfour? A: Winston Churchill.\n",
      "\n",
      "Q: Who was the next British Prime Minister after Arthur Balfour? A: Winston Churchill.\n",
      "\n",
      "Q: Who was the next British Prime Minister after Arthur Balfour? A: Winston Churchill.\n",
      "\n",
      "Q: Who was the next British Prime Minister after Arthur Balfour? A: Winston Churchill.\n",
      "\n",
      "Q: Who was the next British Prime Minister after Arthur Balfour? A: Winston Churchill.\n",
      "\n",
      "Q: Who was the next British Prime Minister after Arthur Balfour? A: Winston Churchill.\n",
      "\n",
      "Q: Who was the next British Prime Minister after Arthur Balfour? A: Winston Churchill.\n",
      "\n",
      "Q: Who was the next British Prime Minister after Arthur Balfour? A: Winston Churchill.\n",
      "\n",
      "Q: Who was the next British Prime Minister after Arthur Balfour? A: Winston Churchill.\n",
      "\n",
      "Q: Who was the next British Prime Minister after Arthur Balf\n",
      "-------------------------\n",
      "Q: Who had a 70s No 1 hit with Kiss You All Over? A:\n",
      "True answer: Exile\n",
      "Model output:  The Beatles\n",
      "\n",
      "The Beatles were the first band to have a No 1 single in the UK, with their cover of Kiss You All Over in 1970.\n",
      "\n",
      "The song was written by Paul McCartney and George Harrison, and was released as a single in the UK on 7 June 1970.\n",
      "\n",
      "It was the first single to be released by the band since their last single, I Want To Hold Your Hand, had been released in March 1969.\n",
      "\n",
      "The song was a huge hit in the UK, reaching No 1 on the UK Singles Chart for three weeks in July 1970.\n",
      "\n",
      "It was also the first single to be released by the band since their last single, I Want To Hold Your Hand, had been released in March 1969.\n",
      "\n",
      "The song was a huge hit in the UK, reaching No 1 on the UK Singles Chart for three weeks in July 1970.\n",
      "\n",
      "It was also the first single to be released by the band since their last single, I Want To Hold Your Hand, had been released in March 1969.\n",
      "\n",
      "The song was a huge hit in the UK, reaching No 1 on the UK Singles Chart for three weeks in\n",
      "-------------------------\n",
      "Q: What claimed the life of singer Kathleen Ferrier? A:\n",
      "True answer: Cancer\n",
      "Model output:  Kathleen Ferrier, a singer and actress, was found dead in her home in Los Angeles on March 1, 2009. She was 46.\n",
      "\n",
      "Q: What was the cause of death? A: Ferrier died of a heart attack.\n",
      "\n",
      "Q: Who was Kathleen Ferrier? A: Ferrier was a singer and actress. She was born Kathleen Ferrier in New York City on July 17, 1964. She was the daughter of actress and singer Kathleen Ferrier and her husband, actor and director Michael Ferrier. Ferrier was a member of the musical group The Ferriers. She was also a singer and actress. Ferrier was married to actor Michael Ferrier from 1991 to 2007. She was the mother of actor and director Michael Ferrier Jr. and actor Michael Ferrier III.\n",
      "\n",
      "Q: What was her career? A: Ferrier was a singer and actress. She was a member of the musical group The Ferriers. She was also a singer and actress. Ferrier was married to actor Michael Ferrier from 1991 to 2007. She was the mother of actor and director Michael Ferrier Jr. and actor Michael Ferrier III.\n",
      "\n",
      "Q: What was\n",
      "-------------------------\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from all the answers being wrong, after the answer, the model continues to either repeat the question/answer or asks new questions. To account for this issue a better prompt format is needed. To account for this issue, the paper (page 16) proposes to trim all generations by pattern matching for the bad-words \"Q:\", \"Question:\", \"QUESTION:\", \"questions:\". This means that those tokens will not be part of the generation. \n",
    "\n",
    "Another problem is that \" Q:\" and \" A:\" are tokenized with a leading space. This leads to the problem that each generation starts with a space and therefore the probability of the sequence is distorted. As [this](https://github.com/meta-llama/llama/issues/217#issuecomment-1774147331) discussion on GitHub proposes, I remove all spaces."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T12:54:28.385906Z",
     "start_time": "2024-06-07T12:54:28.371905Z"
    }
   },
   "source": [
    "print(f\"Tokenization for 'Q:': {tokenizer('Q:')}\\t for ' Q:': {tokenizer(' Q:')}\")\n",
    "print(f\"Tokenization for 'A:': {tokenizer('A:')}\\t for ' A:': {tokenizer(' A:')}\")\n",
    "print()\n",
    "example_answer = \"The Chipmunks Q: Who was the man behind The Chipmunks? A:\"\n",
    "print(f\"Excerpt of example answer{example_answer}\")\n",
    "tokenized_example_answer = tokenizer(example_answer)\n",
    "print(f\"Tokenized example answer: {tokenized_example_answer}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization for 'Q:': {'input_ids': [2, 1864, 35], 'attention_mask': [1, 1, 1]}\t for ' Q:': {'input_ids': [2, 1209, 35], 'attention_mask': [1, 1, 1]}\n",
      "Tokenization for 'A:': {'input_ids': [2, 250, 35], 'attention_mask': [1, 1, 1]}\t for ' A:': {'input_ids': [2, 83, 35], 'attention_mask': [1, 1, 1]}\n",
      "\n",
      "Excerpt of example answerThe Chipmunks Q: Who was the man behind The Chipmunks? A:\n",
      "Tokenized example answer: {'input_ids': [2, 133, 11055, 20614, 2258, 1209, 35, 3394, 21, 5, 313, 639, 20, 11055, 20614, 2258, 116, 83, 35], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "As you can see, the series 1209, 35 and the series 83, 35 appear in the tokenized example answer, but the series 1864, 35 and the series 250, 35 for the token without leading space don't appear. When removing the spaces, the tokenizer has problems in tokenizing \"Q:\" and \"A:\" as one token. As a result, I change them to \"QUESTION:\" and \"ANSWER:\"."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Better prompt format/Changes in generation\n",
    "- QUESTION:, ANSWER: instead of Q:, A:\n",
    "- No empty spaces between QUESTION:, ANSWER:\n",
    "- Paper (page 16): Few-shot prompting with n=10\n",
    "- New line after each sample in few shot prompt \n",
    "- New line character as eos token id (this makes sense as TriviaQA provides short answers in one line) --> Generation stops, once a \\n is encountered\n",
    "- After a lot of tries and evaluating answers: Improved the list of stop tokens\n",
    "- Set maximum token length that generated answer can have to smaller value as answers in TriviaQA are also quite short"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T16:06:20.918058Z",
     "start_time": "2024-06-07T16:06:20.872057Z"
    }
   },
   "source": [
    "# Few shot prompt\n",
    "selected_training_data = data_trivia_train.select(range(0, 10))\n",
    "ten_shot_prompt = \"\"\n",
    "for data in selected_training_data:\n",
    "    ten_shot_prompt += \"QUESTION:\" + data[\"question\"] + \"ANSWER:\" + data[\"answer\"][\"value\"] + \"\\n\"\n",
    "\n",
    "# Define stop tokens, use token on position 1 bc position 0 is special token\n",
    "stop_tokens = [\"Q:\", \"Question:\", \"QUESTION:\", \"questions:\", \" Q:\", \" Question:\", \" QUESTION:\", \" questions:\",\n",
    "               \"A:\", \"Answer:\", \"ANSWER:\", \"answers:\", \" A:\", \" Answer:\", \" ANSWER:\", \" answers:\", \"Answers:\",\n",
    "               \" Answers:\",\n",
    "               \"Topic:\", \" Topic:\", \"TOPIC:\", \" TOPIC:\", \".\", \" .\", \"...\", \" ...\", \"?\", \" ?\", \":\", \" :\", \"!\", \" !\"]\n",
    "stop_tokens = [[tokenizer(stop_token)[\"input_ids\"][1]] for stop_token in stop_tokens]\n",
    "\n",
    "# Define eos token\n",
    "eos_token = tokenizer(\"\\n\")[\"input_ids\"][1]\n",
    "tokenizer.pad_token_id = eos_token\n",
    "tokenizer.eos_token_id = eos_token\n",
    "\n",
    "# Maximum token length that generated answer can have\n",
    "max_new_tokens = 32"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "That means, that the few shot prompt looks like this + \"QUESTION:<question we really want to ask>ANSWER:\". In the following, only the question we really want to ask is printed out."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T16:06:20.934059Z",
     "start_time": "2024-06-07T16:06:20.919058Z"
    }
   },
   "cell_type": "code",
   "source": "print(ten_shot_prompt)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION:Which American-born Sinclair won the Nobel Prize for Literature in 1930?ANSWER:Sinclair Lewis\n",
      "QUESTION:Where in England was Dame Judi Dench born?ANSWER:York\n",
      "QUESTION:In which decade did Billboard magazine first publish and American hit chart?ANSWER:30s\n",
      "QUESTION:From which country did Angola achieve independence in 1975?ANSWER:Portugal\n",
      "QUESTION:Which city does David Soul come from?ANSWER:Chicago\n",
      "QUESTION:Who won Super Bowl XX?ANSWER:Chicago Bears\n",
      "QUESTION:Which was the first European country to abolish capital punishment?ANSWER:Norway\n",
      "QUESTION:In which country did he widespread use of ISDN begin in 1988?ANSWER:Japan\n",
      "QUESTION:What is Bruce Willis' real first name?ANSWER:Walter\n",
      "QUESTION:Which William wrote the novel Lord Of The Flies?ANSWER:Golding\n",
      "\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Try generating sequences again with the new prompt format:"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T13:02:29.580024Z",
     "start_time": "2024-06-07T13:02:27.328821Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(10):\n",
    "    question = ten_shot_prompt + \"QUESTION:\" + data_trivia_val[i][\"question\"] + \"ANSWER:\"\n",
    "    answer = data_trivia_val[i][\"answer\"][\"value\"]\n",
    "\n",
    "    # As mentioned above, only print question\n",
    "    print(f\"Question: {data_trivia_val[i]['question']}\")\n",
    "    print(f\"True Answer: {answer}\")\n",
    "\n",
    "    inputs = tokenizer(question, padding=False, truncation=False, return_tensors=\"pt\").to(device)\n",
    "    length_input = inputs[\"input_ids\"].shape[1]\n",
    "\n",
    "    # Generate sequence by always taking token with max probability (greedy)\n",
    "    output_generate = model.generate(inputs.input_ids,\n",
    "                                     max_new_tokens=max_new_tokens,\n",
    "                                     eos_token_id=eos_token,\n",
    "                                     bad_words_ids=stop_tokens)\n",
    "    output = tokenizer.batch_decode(output_generate[0][length_input:], skip_special_tokens=True)\n",
    "    print(f\"Model Output: {''.join(output)}\")\n",
    "    print(\"-------------------------\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who was the man behind The Chipmunks?\n",
      "True Answer: David Seville\n",
      "Model Output: Walt Disney\n",
      "\n",
      "-------------------------\n",
      "Question: Which Lloyd Webber musical premiered in the US on 10th December 1993?\n",
      "True Answer: Sunset Boulevard\n",
      "Model Output: The Phantom Of The Opera\n",
      "\n",
      "-------------------------\n",
      "Question: Who was the next British Prime Minister after Arthur Balfour?\n",
      "True Answer: Campbell-Bannerman\n",
      "Model Output: John Major\n",
      "\n",
      "-------------------------\n",
      "Question: Who had a 70s No 1 hit with Kiss You All Over?\n",
      "True Answer: Exile\n",
      "Model Output: The Beatles\n",
      "\n",
      "-------------------------\n",
      "Question: What claimed the life of singer Kathleen Ferrier?\n",
      "True Answer: Cancer\n",
      "Model Output: The Beatles\n",
      "\n",
      "-------------------------\n",
      "Question: Rita Coolidge sang the title song for which Bond film?\n",
      "True Answer: Octopussy\n",
      "Model Output: Live And Let Die\n",
      "\n",
      "-------------------------\n",
      "Question: What was the last US state to reintroduce alcohol after prohibition?\n",
      "True Answer: Utah\n",
      "Model Output: New York\n",
      "\n",
      "-------------------------\n",
      "Question: Which actress was voted Miss Greenwich Village in 1942?\n",
      "True Answer: Lauren Bacall\n",
      "Model Output: Betty Grable\n",
      "\n",
      "-------------------------\n",
      "Question: What is the Japanese share index called?\n",
      "True Answer: Nikkei\n",
      "Model Output: The Nikkei\n",
      "\n",
      "-------------------------\n",
      "Question: What was the name of Michael Jackson's autobiography written in 1988?\n",
      "True Answer: Moonwalk\n",
      "Model Output: Billie Jean\n",
      "\n",
      "-------------------------\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The format of the answers looks good - we can argue about their correctness though (except for one example).\n",
    "\n",
    "## Include probability of generated output sequence and number of output tokens\n",
    "Number of output tokens used to calculate length-normalized predictive entropy\n",
    "\n",
    "For calculating the probability of generated output, see: https://discuss.huggingface.co/t/announcement-generation-get-probabilities-for-generated-output/30075"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T14:14:27.210109Z",
     "start_time": "2024-06-07T14:14:19.074445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in [100, 200, 300]:\n",
    "    question = ten_shot_prompt + \"QUESTION:\" + data_trivia_val[i][\"question\"] + \"ANSWER:\"\n",
    "    answer = data_trivia_val[i][\"answer\"][\"value\"]\n",
    "\n",
    "    # As mentioned above, only print question\n",
    "    print(f\"Question: {data_trivia_val[i]['question']}\")\n",
    "    print(f\"True Answer: {answer}\")\n",
    "\n",
    "    inputs = tokenizer(question, padding=False, truncation=False, return_tensors=\"pt\").to(device)\n",
    "    length_input = inputs[\"input_ids\"].shape[1]\n",
    "\n",
    "    output_generate = model.generate(inputs.input_ids,\n",
    "                                     max_new_tokens=max_new_tokens,\n",
    "                                     eos_token_id=eos_token,\n",
    "                                     bad_words_ids=stop_tokens,\n",
    "                                     return_dict_in_generate=True,\n",
    "                                     output_scores=True)\n",
    "    output = tokenizer.batch_decode(output_generate.sequences[0][length_input:], skip_special_tokens=True)\n",
    "\n",
    "    # Calculate probability and count output tokens\n",
    "    n_output_tokens = 0\n",
    "    transition_scores = model.compute_transition_scores(output_generate.sequences,\n",
    "                                                        output_generate.scores,\n",
    "                                                        normalize_logits=True)\n",
    "    generated_tokens = output_generate.sequences[:, length_input:]\n",
    "    prob_output = 1\n",
    "    for tok, score in zip(generated_tokens[0], transition_scores[0]):\n",
    "        print(\n",
    "            f\"{tok:5d} | {repr(tokenizer.decode(tok)):12s} | {score.cpu().numpy():.4f} | {np.exp(score.cpu().numpy()):.2%}\")\n",
    "        prob_output *= np.exp(score.cpu().numpy())\n",
    "        n_output_tokens += 1\n",
    "\n",
    "    print(f\"Model Output: {''.join(output)}\")\n",
    "    print(f\"Probability of output: {prob_output}\")\n",
    "    print(f\"Number of output tokens: {n_output_tokens}\")\n",
    "    print(\"-------------------------\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Which Oscar-nominated film had You Sexy Thing as its theme song?\n",
      "True Answer: The Full Monty\n",
      "  133 | 'The'        | -1.9775 | 13.84%\n",
      " 6748 | ' Dep'       | -3.2594 | 3.84%\n",
      "26587 | 'arted'      | -0.0164 | 98.38%\n",
      "50118 | '\\n'         | -0.0608 | 94.10%\n",
      "Model Output: The Departed\n",
      "\n",
      "Probability of output: 0.004921769236503534\n",
      "Number of output tokens: 4\n",
      "-------------------------\n",
      "Question: Who was the first American to travel faster than the speed of sound?\n",
      "True Answer: Chuck Yeager\n",
      "  863 | 'J'          | -3.3494 | 3.51%\n",
      "17773 | 'ules'       | -1.1234 | 32.52%\n",
      " 3060 | ' Ver'       | -0.0153 | 98.48%\n",
      "  858 | 'ne'         | -0.0002 | 99.98%\n",
      "50118 | '\\n'         | -0.0715 | 93.10%\n",
      "Model Output: Jules Verne\n",
      "\n",
      "Probability of output: 0.010463550529798284\n",
      "Number of output tokens: 5\n",
      "-------------------------\n",
      "Question: What is the longest word can be typed using only the top row of letters on a typewriter?\n",
      "True Answer: Typewriter\n",
      "  176 | '2'          | -3.7893 | 2.26%\n",
      "    6 | ','          | -0.4968 | 60.85%\n",
      "  151 | '000'        | -2.2945 | 10.08%\n",
      " 3768 | ' characters' | -1.1986 | 30.16%\n",
      "50118 | '\\n'         | -0.1074 | 89.82%\n",
      "Model Output: 2,000 characters\n",
      "\n",
      "Probability of output: 0.00037576269509422716\n",
      "Number of output tokens: 5\n",
      "-------------------------\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Sampling multiple answers\n",
    "See: https://huggingface.co/docs/transformers/en/generation_strategies and https://huggingface.co/blog/how-to-generate\n",
    "### Setup\n",
    "The following setup remains the same for different sampling techniques. I sample 10 answers per question (see page 8 in paper).\n",
    "\n",
    "The sampled list of tokens includes the special token <pad> for padding purposes. As special tokens should not be included in the calculation of the probability of the output, they are excluded (also in the count of output tokens). Special tokens can be identified by having a < and a >. \n",
    "\n",
    "For example: \n",
    "['D', 'ery', 'ck', ' Gibson', '\\n', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
    "\n",
    "Here, only the first 5 tokens should be included."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T16:06:20.950066Z",
     "start_time": "2024-06-07T16:06:20.935059Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# How many questions to test in this jupyter notebook\n",
    "n_questions = 10\n",
    "\n",
    "# How many answers to sample (here 10, see page 8 in paper)\n",
    "n_sample = 10\n",
    "\n",
    "# Temperature for sampling (used in paper: 0.25, 0.5, 1, 1.5)\n",
    "temperature = 0.5"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T16:06:20.965568Z",
     "start_time": "2024-06-07T16:06:20.952061Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_probability_sequence(output_generate, length_input, idx=0, beam_sampling=False, print_scores=False):\n",
    "    \"\"\"\n",
    "    Calculates the probability of a generated sequence, excludes special tokens, EOS token\n",
    "    :param output_generate: output of function generate(...)\n",
    "    :param length_input: length of input_ids to function generate(...)\n",
    "    :param idx: if multiple sequences got generated, index of the sequence for that probability should be calculated (0 if only one sequence)\n",
    "    :param beam_sampling: Set true if you want to calculate the probability of a sequence created with beam sampling\n",
    "    :param print_scores: Set True if table with token, decoded token, score and probability should be printed out\n",
    "    :return: Probability of generated sequence, number of output tokens\n",
    "    \"\"\"\n",
    "\n",
    "    if not beam_sampling:\n",
    "        transition_scores = model.compute_transition_scores(output_generate.sequences, output_generate.scores,\n",
    "                                                            normalize_logits=True)\n",
    "    \n",
    "    else:\n",
    "        transition_scores = model.compute_transition_scores(output_generate.sequences, output_generate.scores,\n",
    "                                                            output_generate.beam_indices, normalize_logits=True)\n",
    "    \n",
    "    generated_tokens = output_generate.sequences[:, length_input:]\n",
    "    prob_output = 1\n",
    "    n_output_tokens = 0\n",
    "\n",
    "    for tok, score in zip(generated_tokens[idx], transition_scores[idx]):\n",
    "        decoded_token = tokenizer.decode(tok)\n",
    "        if print_scores:\n",
    "            print(\n",
    "                f\"{tok:5d} | {repr(decoded_token):12s} | {score.cpu().numpy():.4f} | {np.exp(score.cpu().numpy()):.2%}\")\n",
    "\n",
    "        # Don't include special tokens in generation\n",
    "        if \"<\" not in decoded_token or \">\" not in decoded_token:\n",
    "            prob_output *= np.exp(score.cpu().numpy())\n",
    "            n_output_tokens += 1        \n",
    "\n",
    "    return prob_output, n_output_tokens"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Multinomial sampling"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T14:25:19.229033Z",
     "start_time": "2024-06-07T14:18:31.340867Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(n_questions):\n",
    "    question = ten_shot_prompt + \"QUESTION:\" + data_trivia_val[i][\"question\"] + \"ANSWER:\"\n",
    "    answer = data_trivia_val[i][\"answer\"][\"value\"]\n",
    "\n",
    "    # As mentioned above, only print question\n",
    "    print(f\"Question: {data_trivia_val[i]['question']}\")\n",
    "    print(f\"True Answer: {answer}\")\n",
    "\n",
    "    inputs = tokenizer(question, padding=False, truncation=False, return_tensors=\"pt\").to(device)\n",
    "    length_input = inputs[\"input_ids\"].shape[1]\n",
    "\n",
    "    # Sample sequences\n",
    "    output_generate = model.generate(inputs.input_ids,\n",
    "                                     max_new_tokens=max_new_tokens,\n",
    "                                     eos_token_id=eos_token,\n",
    "                                     bad_words_ids=stop_tokens,\n",
    "                                     return_dict_in_generate=True,\n",
    "                                     output_scores=True,\n",
    "                                     do_sample=True,\n",
    "                                     num_return_sequences=n_sample,\n",
    "                                     temperature=temperature,\n",
    "                                     top_p=0.9)\n",
    "\n",
    "    for n_sequence in range(n_sample):\n",
    "        output = tokenizer.batch_decode(output_generate.sequences[n_sequence][length_input:],\n",
    "                                        skip_special_tokens=True)\n",
    "\n",
    "        # Calculating probability of sequence\n",
    "        prob_output, n_output_tokens = calculate_probability_sequence(output_generate, length_input, idx=n_sequence,\n",
    "                                                                      print_scores=False)\n",
    "\n",
    "        # Print out result\n",
    "        output_string = \"\".join(output).replace(\"\\n\", \"\")\n",
    "        print(f\"Sequence ({n_sequence}): {output_string} (P: {prob_output:.6}, Length output: {n_output_tokens})\")\n",
    "    print(\"-------------------------\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who was the man behind The Chipmunks?\n",
      "True Answer: David Seville\n",
      "Sequence (0): Ralph Bakshi (P: 0.0262715, Length output: 5)\n",
      "Sequence (1): Morten Tyldum (P: 0.0230432, Length output: 7)\n",
      "Sequence (2): Holtzman (P: 0.00350962, Length output: 4)\n",
      "Sequence (3): Barrister (P: 7.56197e-05, Length output: 4)\n",
      "Sequence (4): Steven Spielberg (P: 0.0162728, Length output: 3)\n",
      "Sequence (5): Ralph Bakshi (P: 0.0262715, Length output: 5)\n",
      "Sequence (6): Don Mancini (P: 0.00121557, Length output: 5)\n",
      "Sequence (7): Travis (P: 0.00503784, Length output: 3)\n",
      "Sequence (8): Thomas Middleditch (P: 0.0646235, Length output: 5)\n",
      "Sequence (9): Horton Hears a Who (P: 0.00504698, Length output: 8)\n",
      "-------------------------\n",
      "Question: Which Lloyd Webber musical premiered in the US on 10th December 1993?\n",
      "True Answer: Sunset Boulevard\n",
      "Sequence (0): The Phantom Of The Opera (P: 0.810635, Length output: 6)\n",
      "Sequence (1): The Phantom Of The Opera (P: 0.810635, Length output: 6)\n",
      "Sequence (2): The Phantom Of The Opera (P: 0.810635, Length output: 6)\n",
      "Sequence (3): The Phantom Of The Opera (P: 0.810635, Length output: 6)\n",
      "Sequence (4): The Phantom Of The Opera (P: 0.810635, Length output: 6)\n",
      "Sequence (5): Lloyd Webber's (P: 0.0023832, Length output: 7)\n",
      "Sequence (6): The Phantom Of The Opera (P: 0.810635, Length output: 6)\n",
      "Sequence (7): The Phantom Of The Opera (P: 0.810635, Length output: 6)\n",
      "Sequence (8): The Phantom Of The Opera (P: 0.810635, Length output: 6)\n",
      "Sequence (9): The Phantom Of The Opera (P: 0.810635, Length output: 6)\n",
      "-------------------------\n",
      "Question: Who was the next British Prime Minister after Arthur Balfour?\n",
      "True Answer: Campbell-Bannerman\n",
      "Sequence (0): Margaret Thatcher (P: 0.139595, Length output: 4)\n",
      "Sequence (1): Churchill (P: 0.0531442, Length output: 3)\n",
      "Sequence (2): John Major (P: 0.210629, Length output: 3)\n",
      "Sequence (3): Lord Mountbatten (P: 0.00582019, Length output: 5)\n",
      "Sequence (4): John Major (P: 0.210629, Length output: 3)\n",
      "Sequence (5): David Lloyd George (P: 0.207048, Length output: 4)\n",
      "Sequence (6): Lord Salisbury (P: 0.00521772, Length output: 4)\n",
      "Sequence (7): Margaret Thatcher (P: 0.139595, Length output: 4)\n",
      "Sequence (8): Winston Churchill (P: 0.0832715, Length output: 4)\n",
      "Sequence (9): John Major (P: 0.210629, Length output: 3)\n",
      "-------------------------\n",
      "Question: Who had a 70s No 1 hit with Kiss You All Over?\n",
      "True Answer: Exile\n",
      "Sequence (0): The Kinks (P: 0.0280271, Length output: 4)\n",
      "Sequence (1): The Eagles (P: 0.0142189, Length output: 3)\n",
      "Sequence (2): The Four Seasons (P: 0.00615376, Length output: 4)\n",
      "Sequence (3): Donna Summer (P: 0.00990098, Length output: 4)\n",
      "Sequence (4): The Bee Gees (P: 0.055419, Length output: 5)\n",
      "Sequence (5): The Police (P: 0.119976, Length output: 3)\n",
      "Sequence (6): The Beatles (P: 0.250055, Length output: 3)\n",
      "Sequence (7): Sonic Youth (P: 0.000613882, Length output: 4)\n",
      "Sequence (8): The Beatles (P: 0.250055, Length output: 3)\n",
      "Sequence (9): The Bee Gees (P: 0.055419, Length output: 5)\n",
      "-------------------------\n",
      "Question: What claimed the life of singer Kathleen Ferrier?\n",
      "True Answer: Cancer\n",
      "Sequence (0): Her husband (P: 0.121648, Length output: 3)\n",
      "Sequence (1): Suicide (P: 0.105157, Length output: 3)\n",
      "Sequence (2): Bobby Kennedy (P: 0.0170211, Length output: 4)\n",
      "Sequence (3): Suicide (P: 0.105157, Length output: 3)\n",
      "Sequence (4): Her husband (P: 0.121648, Length output: 3)\n",
      "Sequence (5): She was a singer (P: 0.00749089, Length output: 5)\n",
      "Sequence (6): Suicide (P: 0.105157, Length output: 3)\n",
      "Sequence (7): Her husband (P: 0.121648, Length output: 3)\n",
      "Sequence (8): The Beatles (P: 0.199094, Length output: 3)\n",
      "Sequence (9): Singer (P: 0.0282504, Length output: 3)\n",
      "-------------------------\n",
      "Question: Rita Coolidge sang the title song for which Bond film?\n",
      "True Answer: Octopussy\n",
      "Sequence (0): Live And Let Die (P: 0.231547, Length output: 5)\n",
      "Sequence (1): Moonraker (P: 0.188107, Length output: 4)\n",
      "Sequence (2): Goldfinger (P: 0.216991, Length output: 3)\n",
      "Sequence (3): The Spy Who Loved Me (P: 0.0618612, Length output: 7)\n",
      "Sequence (4): Dr No (P: 0.102011, Length output: 3)\n",
      "Sequence (5): Goldfinger (P: 0.216991, Length output: 3)\n",
      "Sequence (6): Live And Let Die (P: 0.231547, Length output: 5)\n",
      "Sequence (7): Dr No (P: 0.102011, Length output: 3)\n",
      "Sequence (8): Thunderball (P: 0.0563787, Length output: 3)\n",
      "Sequence (9): Thunderball (P: 0.0563787, Length output: 3)\n",
      "-------------------------\n",
      "Question: What was the last US state to reintroduce alcohol after prohibition?\n",
      "True Answer: Utah\n",
      "Sequence (0): California (P: 0.0740538, Length output: 2)\n",
      "Sequence (1): Indiana (P: 0.0205803, Length output: 2)\n",
      "Sequence (2): Mississippi (P: 0.107083, Length output: 4)\n",
      "Sequence (3): New Hampshire (P: 0.0595788, Length output: 3)\n",
      "Sequence (4): New Mexico (P: 0.0339604, Length output: 3)\n",
      "Sequence (5): Mississippi (P: 0.107083, Length output: 4)\n",
      "Sequence (6): Mississippi (P: 0.107083, Length output: 4)\n",
      "Sequence (7): Nevada (P: 0.0415116, Length output: 3)\n",
      "Sequence (8): Mississippi (P: 0.107083, Length output: 4)\n",
      "Sequence (9): Arizona (P: 0.0250683, Length output: 2)\n",
      "-------------------------\n",
      "Question: Which actress was voted Miss Greenwich Village in 1942?\n",
      "True Answer: Lauren Bacall\n",
      "Sequence (0): Betty Grable (P: 0.15468, Length output: 5)\n",
      "Sequence (1): Juliette Binoche (P: 0.00219518, Length output: 6)\n",
      "Sequence (2): Carole Lombard (P: 0.0194751, Length output: 5)\n",
      "Sequence (3): Marilyn Monroe (P: 0.0336679, Length output: 5)\n",
      "Sequence (4): Jane Russell (P: 0.0146751, Length output: 3)\n",
      "Sequence (5): Katharine Hepburn (P: 0.0161223, Length output: 6)\n",
      "Sequence (6): Betty Grable (P: 0.15468, Length output: 5)\n",
      "Sequence (7): Natalie Wood (P: 0.00632212, Length output: 4)\n",
      "Sequence (8): Betty Grable (P: 0.15468, Length output: 5)\n",
      "Sequence (9): Yvonne De Carlo (P: 0.0153678, Length output: 6)\n",
      "-------------------------\n",
      "Question: What is the Japanese share index called?\n",
      "True Answer: Nikkei\n",
      "Sequence (0): Nikkei 225 (P: 0.210093, Length output: 5)\n",
      "Sequence (1): The Nikkei (P: 0.341927, Length output: 5)\n",
      "Sequence (2): Nikkei 225 (P: 0.210093, Length output: 5)\n",
      "Sequence (3):  Nikkei (P: 0.0237494, Length output: 4)\n",
      "Sequence (4): Nikkei (P: 0.223757, Length output: 4)\n",
      "Sequence (5): Nikkei 225 (P: 0.210093, Length output: 5)\n",
      "Sequence (6): The Nikkei (P: 0.341927, Length output: 5)\n",
      "Sequence (7): The Nikkei (P: 0.341927, Length output: 5)\n",
      "Sequence (8): Nikkei 225 (P: 0.210093, Length output: 5)\n",
      "Sequence (9): The Nikkei (P: 0.341927, Length output: 5)\n",
      "-------------------------\n",
      "Question: What was the name of Michael Jackson's autobiography written in 1988?\n",
      "True Answer: Moonwalk\n",
      "Sequence (0): The Thriller (P: 0.0353815, Length output: 4)\n",
      "Sequence (1): Thriller (P: 0.342185, Length output: 4)\n",
      "Sequence (2): Bad (P: 0.114491, Length output: 2)\n",
      "Sequence (3): This Is It (P: 0.0382957, Length output: 4)\n",
      "Sequence (4): Billie Jean (P: 0.3261, Length output: 4)\n",
      "Sequence (5): The Thriller (P: 0.0353815, Length output: 4)\n",
      "Sequence (6): Billie Jean (P: 0.3261, Length output: 4)\n",
      "Sequence (7): Thriller (P: 0.342185, Length output: 4)\n",
      "Sequence (8): Billie Jean (P: 0.3261, Length output: 4)\n",
      "Sequence (9): Billie Jean (P: 0.3261, Length output: 4)\n",
      "-------------------------\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Multinomial Beam Sampling\n",
    "n_sample highest scoring beams are returned"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T16:34:21.167813Z",
     "start_time": "2024-06-07T16:06:20.967568Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(n_questions):\n",
    "    question = ten_shot_prompt + \"QUESTION:\" + data_trivia_val[i][\"question\"] + \"ANSWER:\"\n",
    "    answer = data_trivia_val[i][\"answer\"][\"value\"]\n",
    "\n",
    "    # As mentioned above, only print question\n",
    "    print(f\"Question: {data_trivia_val[i]['question']}\")\n",
    "    print(f\"True Answer: {answer}\")\n",
    "\n",
    "    inputs = tokenizer(question, padding=False, truncation=False, return_tensors=\"pt\").to(device)\n",
    "    length_input = inputs[\"input_ids\"].shape[1]\n",
    "\n",
    "    # Sample sequences\n",
    "    output_generate = model.generate(inputs.input_ids,\n",
    "                                     max_new_tokens=max_new_tokens,\n",
    "                                     eos_token_id=eos_token,\n",
    "                                     bad_words_ids=stop_tokens,\n",
    "                                     return_dict_in_generate=True,\n",
    "                                     output_scores=True,\n",
    "                                     do_sample=True,\n",
    "                                     num_beams=2 * n_sample,\n",
    "                                     num_return_sequences=n_sample)\n",
    "\n",
    "    for n_sequence in range(n_sample):\n",
    "        output = tokenizer.batch_decode(output_generate.sequences[n_sequence][length_input:],\n",
    "                                        skip_special_tokens=True)\n",
    "\n",
    "        # Calculating probability of sequence\n",
    "        prob_output, n_output_tokens = calculate_probability_sequence(output_generate, length_input, beam_sampling=True, idx=n_sequence,\n",
    "                                                                      print_scores=False)\n",
    "\n",
    "        # Print out result\n",
    "        output_string = ''.join(output).replace(\"\\n\", \"\")\n",
    "        print(f\"Sequence ({n_sequence}): {output_string} (P: {prob_output:.6}, Length output: {n_output_tokens})\")\n",
    "    print(\"-------------------------\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who was the man behind The Chipmunks?\n",
      "True Answer: David Seville\n",
      "Sequence (0): Sylvester Stallone (P: 0.000796802, Length output: 7)\n",
      "Sequence (1): John Lasseter (P: 0.00728878, Length output: 5)\n",
      "Sequence (2): John Lasseter (P: 0.00728878, Length output: 5)\n",
      "Sequence (3): Lemony Snicket (P: 0.00170559, Length output: 6)\n",
      "Sequence (4): John Lasseter, the creator of the Chipmunks, is also the co-founder of Pixar, the animation studio behind The Incredibles (P: 4.56739e-16, Length output: 31)\n",
      "Sequence (5): John Lasseter, the creator of the Chipmunks, is also the co-founder of Pixar, the animation studio behind Toy Story and Finding Nemo (P: 1.27818e-16, Length output: 32)\n",
      "Sequence (6): John Lasseter, the creator of the Chipmunks, is also the co-founder of Pixar, the animation studio behind Toy Story, Finding Nemo (P: 1.29014e-16, Length output: 32)\n",
      "Sequence (7): Ralph Bakshi (P: 0.0060907, Length output: 5)\n",
      "Sequence (8): John Lasseter, the creator of the Chipmunks, is also the co-founder of Pixar, the animation studio behind The Incredibles and Toy (P: 1.04118e-16, Length output: 32)\n",
      "Sequence (9): John Lasseter, the creator of the Chipmunks, is also the co-founder of Pixar, the animation studio behind The Incredibles, Toy (P: 8.34494e-17, Length output: 32)\n",
      "-------------------------\n",
      "Question: Which Lloyd Webber musical premiered in the US on 10th December 1993?\n",
      "True Answer: Sunset Boulevard\n",
      "Sequence (0): The Phantom Of The Opera (P: 0.0887935, Length output: 6)\n",
      "Sequence (1): The Phantom Of The Opera (P: 0.0887935, Length output: 6)\n",
      "Sequence (2): The Phantom Of The Opera (P: 0.0887935, Length output: 6)\n",
      "Sequence (3): The Phantom Of The Opera (P: 0.0887935, Length output: 6)\n",
      "Sequence (4): The Phantom Of The Opera (P: 0.0887935, Length output: 6)\n",
      "Sequence (5): The Phantom Of The Opera (P: 0.0887935, Length output: 6)\n",
      "Sequence (6): Les Miserables (P: 0.0436758, Length output: 5)\n",
      "Sequence (7): Les Miserables (P: 0.0436758, Length output: 5)\n",
      "Sequence (8): Les Misérables (P: 0.0250159, Length output: 5)\n",
      "Sequence (9): Les Misérables (P: 0.0250159, Length output: 5)\n",
      "-------------------------\n",
      "Question: Who was the next British Prime Minister after Arthur Balfour?\n",
      "True Answer: Campbell-Bannerman\n",
      "Sequence (0): Margaret Thatcher (P: 0.0668388, Length output: 4)\n",
      "Sequence (1): Margaret Thatcher (P: 0.0668388, Length output: 4)\n",
      "Sequence (2): Winston Churchill (P: 0.054461, Length output: 4)\n",
      "Sequence (3): Winston Churchill (P: 0.054461, Length output: 4)\n",
      "Sequence (4): Winston Churchill (P: 0.054461, Length output: 4)\n",
      "Sequence (5): David Lloyd George (P: 0.0510328, Length output: 4)\n",
      "Sequence (6): David Lloyd George (P: 0.0510328, Length output: 4)\n",
      "Sequence (7): David Lloyd George (P: 0.0510328, Length output: 4)\n",
      "Sequence (8): David Lloyd George (P: 0.0510328, Length output: 4)\n",
      "Sequence (9): David Attenborough (P: 0.00919424, Length output: 5)\n",
      "-------------------------\n",
      "Question: Who had a 70s No 1 hit with Kiss You All Over?\n",
      "True Answer: Exile\n",
      "Sequence (0): Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss (P: 2.48569e-06, Length output: 32)\n",
      "Sequence (1): Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss (P: 2.48569e-06, Length output: 32)\n",
      "Sequence (2): Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss (P: 2.48569e-06, Length output: 32)\n",
      "Sequence (3): Kiss You All Over, Kiss You All Over, Kiss You All Over, Kiss You All Over, Kiss You All Over, Kiss You All Over, Kiss (P: 1.05703e-06, Length output: 32)\n",
      "Sequence (4): Kiss You All Over, Kiss You All Over, Kiss You All Over, Kiss You All Over, Kiss You All Over, Kiss You All Over (P: 5.94465e-07, Length output: 31)\n",
      "Sequence (5): Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me (P: 2.97457e-07, Length output: 31)\n",
      "Sequence (6): Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me (P: 2.97457e-07, Length output: 31)\n",
      "Sequence (7): Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me (P: 2.97457e-07, Length output: 31)\n",
      "Sequence (8): Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me (P: 4.63043e-07, Length output: 28)\n",
      "Sequence (9): Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me, Kiss Me (P: 4.63043e-07, Length output: 28)\n",
      "-------------------------\n",
      "Question: What claimed the life of singer Kathleen Ferrier?\n",
      "True Answer: Cancer\n",
      "Sequence (0): Kathleen Ferrier (P: 0.0213919, Length output: 6)\n",
      "Sequence (1): Singer Kathleen Ferrier (P: 0.0133871, Length output: 6)\n",
      "Sequence (2): Singer Kathleen Ferrier (P: 0.0133871, Length output: 6)\n",
      "Sequence (3): Singer Kathleen Ferrier (P: 0.0133871, Length output: 6)\n",
      "Sequence (4): Singer Kathleen Ferrier (P: 0.0133871, Length output: 6)\n",
      "Sequence (5): Singer Kathleen Ferrier died of a drug overdose at the age of 27 (P: 1.64968e-08, Length output: 16)\n",
      "Sequence (6): Singer Kathleen Ferrier died of a drug overdose at the age of 36 (P: 1.37118e-08, Length output: 16)\n",
      "Sequence (7): Kathleen Ferrier was killed in a car accident (P: 1.27238e-06, Length output: 12)\n",
      "Sequence (8): Singer Kathleen Ferrier died of a drug overdose at the age of 28 (P: 1.27224e-08, Length output: 16)\n",
      "Sequence (9): Singer Kathleen Ferrier died of a drug overdose at the age of 39 (P: 1.22197e-08, Length output: 16)\n",
      "-------------------------\n",
      "Question: Rita Coolidge sang the title song for which Bond film?\n",
      "True Answer: Octopussy\n",
      "Sequence (0): Live And Let Die (P: 0.0737668, Length output: 5)\n",
      "Sequence (1): Live And Let Die (P: 0.0737668, Length output: 5)\n",
      "Sequence (2): Live And Let Die (P: 0.0737668, Length output: 5)\n",
      "Sequence (3): Live And Let Die (P: 0.0737668, Length output: 5)\n",
      "Sequence (4): Moonraker (P: 0.094518, Length output: 4)\n",
      "Sequence (5): Moonraker (P: 0.094518, Length output: 4)\n",
      "Sequence (6): Moonraker (P: 0.094518, Length output: 4)\n",
      "Sequence (7): Moonraker (P: 0.094518, Length output: 4)\n",
      "Sequence (8): Moonraker (P: 0.094518, Length output: 4)\n",
      "Sequence (9): Moonraker (P: 0.094518, Length output: 4)\n",
      "-------------------------\n",
      "Question: What was the last US state to reintroduce alcohol after prohibition?\n",
      "True Answer: Utah\n",
      "Sequence (0): Mississippi (P: 0.0433697, Length output: 4)\n",
      "Sequence (1): Mississippi (P: 0.0433697, Length output: 4)\n",
      "Sequence (2): Mississippi (P: 0.0433697, Length output: 4)\n",
      "Sequence (3): Alaska (P: 0.0833051, Length output: 3)\n",
      "Sequence (4): Alaska (P: 0.0833051, Length output: 3)\n",
      "Sequence (5): New York (P: 0.0346442, Length output: 3)\n",
      "Sequence (6): New York (P: 0.0346442, Length output: 3)\n",
      "Sequence (7): New York (P: 0.0346442, Length output: 3)\n",
      "Sequence (8): New York (P: 0.0346442, Length output: 3)\n",
      "Sequence (9): Missouri (P: 0.0326552, Length output: 3)\n",
      "-------------------------\n",
      "Question: Which actress was voted Miss Greenwich Village in 1942?\n",
      "True Answer: Lauren Bacall\n",
      "Sequence (0): Betty Grable (P: 0.0361214, Length output: 5)\n",
      "Sequence (1): Dorothy Dandridge (P: 0.00401218, Length output: 7)\n",
      "Sequence (2): Dorothy Dandridge (P: 0.00401218, Length output: 7)\n",
      "Sequence (3): Marlene Dietrich (P: 0.00522724, Length output: 6)\n",
      "Sequence (4): Catherine Deneuve (P: 0.00456218, Length output: 6)\n",
      "Sequence (5): Marilyn Monroe (P: 0.00901621, Length output: 5)\n",
      "Sequence (6): Judy Garland (P: 0.0227527, Length output: 4)\n",
      "Sequence (7): Lillian Gish (P: 0.00662787, Length output: 5)\n",
      "Sequence (8): Juliette Binoche (P: 0.00203899, Length output: 6)\n",
      "Sequence (9): Juliette Binoche (P: 0.00203899, Length output: 6)\n",
      "-------------------------\n",
      "Question: What is the Japanese share index called?\n",
      "True Answer: Nikkei\n",
      "Sequence (0): Nikkei 225 (P: 0.0870008, Length output: 5)\n",
      "Sequence (1): Nikkei 225 (P: 0.0870008, Length output: 5)\n",
      "Sequence (2): Nikkei 225 (P: 0.0870008, Length output: 5)\n",
      "Sequence (3): Nikkei 225 (P: 0.0870008, Length output: 5)\n",
      "Sequence (4): Nikkei 225 (P: 0.0870008, Length output: 5)\n",
      "Sequence (5): Nikkei 225 (P: 0.0870008, Length output: 5)\n",
      "Sequence (6): Nikkei 225 (P: 0.0870008, Length output: 5)\n",
      "Sequence (7): The Nikkei (P: 0.0825726, Length output: 5)\n",
      "Sequence (8): The Nikkei (P: 0.0825726, Length output: 5)\n",
      "Sequence (9): The Nikkei (P: 0.0825726, Length output: 5)\n",
      "-------------------------\n",
      "Question: What was the name of Michael Jackson's autobiography written in 1988?\n",
      "True Answer: Moonwalk\n",
      "Sequence (0): Thriller (P: 0.137927, Length output: 4)\n",
      "Sequence (1): Thriller (P: 0.137927, Length output: 4)\n",
      "Sequence (2): Thriller (P: 0.137927, Length output: 4)\n",
      "Sequence (3): Thriller (P: 0.137927, Length output: 4)\n",
      "Sequence (4): Thriller (P: 0.137927, Length output: 4)\n",
      "Sequence (5): Billie Jean (P: 0.0707904, Length output: 4)\n",
      "Sequence (6): Billie Jean (P: 0.0707904, Length output: 4)\n",
      "Sequence (7): Billie Jean (P: 0.0707904, Length output: 4)\n",
      "Sequence (8): Billie Jean (P: 0.0707904, Length output: 4)\n",
      "Sequence (9): Billie Jean (P: 0.0707904, Length output: 4)\n",
      "-------------------------\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Overall, the quality of generations with beam search looks worse than the one for multimodal sampling. This has mainly three reasons:\n",
    "1) Beam search suffers from repetitive generation. This could be solve by setting no_repeat_ngram_size and early_stopping, however sometimes repetition is desirable \n",
    "2) The generations are longer than the ones for multimodal sampling, however the true answers of the TriviaQA dataset are quite short. \n",
    "3) The generations with beam search seem less diverse. This is also noted in the paper (page 15) and will be visualized later by calculating the diversity scores.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
